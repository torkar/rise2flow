---
title: "Rise 2 Flow: A family of experiments"
subtitle: "A replication package"
author: "Birgit Penzenstadler, Cristina Martinez Montez, and Richard Torkar"
date: "First version: 2021-05-05. Current version: `r Sys.time()`."
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    scroll_highlight: yes
    number_sections: true
bibliography: references.bib
csl: elsevier-harvard.csl
link-citations: true
linkcolor: blue
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

```{r setup2, echo=FALSE, message=FALSE}
library("brms") 
library("plyr") # rm non-duplicates
library("tidyverse") 
library("bayesplot")
library("latex2exp")
library("ggplot2")
library("ggthemes")
library("patchwork") 
library("openxlsx")
library("tidybayes")
library("data.table")
library("here") # make sure Rmd and Rproj root is the same
library(scico)

sl <- scico(palette = "lajolla", n = 9)

rstan::rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

# Introduction

During spring 2021 the Rise 2 Flow study was replicated in yet another experiment `E2`. The setup and execution was very similar to the first instance (`E1`) of the experiment. In the `data/` directory one can find data for both instances `E1/` and `E2/`. In the root of the `data/` directory one can find one XLS file with all relevant data assembled.

The purpose of this document is to show how the analysis of the experiments was done. With this replication package anyone can download and rerun the analysis, and check our assumptions.

The experiment used a number of instruments during the entry, exit, and weekly sessions (additionally personal data was collected during the entry session).

For entry and exit sessions six instruments were used:

* Mindful attention awareness scale (MAAS).^[https://ppc.sas.upenn.edu/resources/questionnaires-researchers/mindful-attention-awareness-scale]
* Scale of positive and negative experience (SPANE).^[https://www.midss.org/content/scale-positive-and-negative-experience-spane-0]
* Personal well-being index (PWB).^[http://www.acqol.com.au/instruments]
* Positive thinking (PST).^[https://www.psytoolkit.org/survey-library/pts.html]
* Self efficacy (SE).^[https://sparqtools.org/mobility-measure/new-general-self-efficacy-scale/]
* Perceived productivity (PP).^[https://www.hcp.med.harvard.edu/hpq/info.php]

For the weekly sessions the WHO-5 well-being index was used (WHO-5).^[https://www.psykiatri-regionh.dk/who-5/who-5-questionnaires/Pages/default.aspx]

To summarize, the experiments were executed according to,

1. An entry survey, at time $t_0$ (MAAS, etc.) with personal data
2. A weekly survey, at time $t_{\text{w}_{1}}, \ldots, t_{\text{w}_{n}}$
3. Daily surveys, at time $t_{\text{d}_{1}}, \ldots, t_{\text{d}_{n}}$ 
4. An exit survey, at time $t_{1}$ (MAAS, etc.)

The main question the study tries to answer is: **Is there a difference in the responses (i.e., higher/lower values on responses), across all or among some instruments, over time?**

## Data cleaning

In order to answer the above question we can first of all compare outcomes at $t_0$ and $t_1$, and condition on personal data, e.g., age and gender. Next, the weekly and daily questions could be used to analyze the trend over time, and perhaps see where a noticeable effect, if it exists, shows up.

### Entry and exit instruments

```{r load_data, echo=TRUE}
d <- read.csv(here("data/cleanedData.csv"), row.names = 1)
dim(d)
```

In total, we have `r dim(d)[1]` rows and `r dim(d)[2]` columns; so not bad at all actually ($N=187$). Each row corresponds to one subject answering either the entry ($t_0$) or the exit ($t_1$) survey. In some cases we have subjects that have only answered one of them!

```{r}
table(table(d$ID) >1)
```

So, $105$ subjects filled out the survey once, and $41$ filled out the entry *and* exit surveys, i.e., in total $146$ subjects participated in both experiments.

There should not be more than $>2$ rows per subject and it should be encoded as an integer for reasons of anonymity.

```{r}
max(table(d$ID))
typeof(d$ID)
```

For each column (variable) we check which values it has and then code it correctly,

```{r}
# MAAS instrument
for(j in 2:16){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("Almost never", "Very infrequently", "Somewhat infrequently", "Somewhat frequently", "Very frequently", "Almost always"), ordered = TRUE))
}

# SPANE instrument
for(j in 17:28){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("Very rarely or never", "Rarely", "Sometimes", "Often", "Very often or always"), ordered = TRUE))
}

# PWB instrument
for(j in 29:36){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("Strongly disagree", "Disagree", "Slightly disagree", "Mixed or neither agree nor disagree", "Slightly agree", "Agree", "Strongly agree"), ordered = TRUE))
}

# PST instrument
for(i in 37:58)
  d[,eval(i)] <- ifelse(d[eval(i)] == 'Yes', 1, 0)

# SEQ instrument
for(j in 59:68){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("Not true","Hardly true","Rather true","Exactly true"), ordered = TRUE))
}

# PP instrument
for(j in 69:75){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("None of the time","A little of the time","Some of the time","Most of the time","All of the time"), ordered = TRUE))
}
for(j in 76:78){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("1","2","3","4","5","6","7","8","9","10"), ordered = TRUE))
}
for(j in 79:79){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("You were a lot worse than other workers","You were a little worse than other workers","You were somewhat worse than other workers","You were about average","You were somewhat better than other workers","You were a little better than other workers","You were a lot better than other workers"), ordered = TRUE))
}

# make sure Age is standardized
d$Age <- scale(d$Age)
```

To summarize, in the first column we have subject ID, then the MAAS instrument ($15$ questions), SPANE ($12$), PWB ($8$), PST ($22$), SE ($10$), PP ($11$), age (standardized), gender ($1/2$), occupation (student or non-students, $1/2$), living condition (four unordered categories), temporal variable ($0/1$ for $t_0 / t_1$), and experiment ($1/2$ for first or second experiment).

### Weekly and daily data

First, load the weekly data set.

```{r}
# drop first index column with `row.names = 1`
weekly <- read.csv(here("data/weekly.csv"), row.names = 1)

str(weekly)
```

We have `r dim(weekly)[1]` rows and `r dim(weekly)[2]` columns. The first column contains a unique ID for each subject. Columns $2$--$6$ are the $5$ questions asked (Likert scale $1,\ldots,6$), Column $7$ indicates if they were part of the 1st (0) or 2nd (1) experiment. Finally, the last column is a sequence indicator, i.e., the first subject answered the questions four times, $1,\ldots,4$, the second subject twice, and so on.

Let's turn our attention to the daily data set,

```{r}
daily <- read.csv(here("data/daily.csv"), row.names = 1)

str(daily)
```

We have `r dim(daily)[1]` rows and `r dim(daily)[2]` columns. The first column is the subject's ID. The response to the daily question comes next (Likert scale $1,\ldots,10$). After that we have an indicator which experiment the subject belongs to and a sequence indicator, as was the case in the weekly data set.

# Model designs

In Appendix \@ref(appA) a comparison of different likelihoods can be found. 

## `weekly` data {.tabset}

If we take a random sample of $32$ subjects we will see how complicated it will be to analyze this. For the first question we have in the weekly survey instrument, for each of the $32$ subjects, we've plotted answers (dots) they provided on a $1,\ldots,6$ Likert scale; then we've drawn a linear model for what we've got.

```{r fig.width=9, fig.height=9}
weekly |>
  filter(ID %in% sample(x = max(weekly$ID), size = 32)) %>%
  ggplot(aes(x = Seq, y = WQ1_1_6)) +
  geom_point() +
  scale_x_continuous(breaks = seq(from = 2, to = 12, by = 2)) +
  scale_y_continuous(breaks = c(2,4,6)) +
  stat_smooth(method = "lm", se = F) +
  ylab("Question 1 (Likert 1 to 6)") +
  xlab("Week number") +
  theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20)) +
  facet_wrap( ~ ID, ncol = 4)
```

### WHO-5: Q1 

#### Prior predictive checks

We want to model the weekly instrument and how it varies over time $t$ (in our case the sequence variable `Seq`). In this case, $t$ will be modeled using a Gaussian Process and then each individual in the dataset will be modeled using a varying intercept (in addition we'll model $\sigma$, called `disc` below, for each experimental session). 

An information theoretical comparison using LOO showed that a model with varying intercepts for each individual had considerably better relative out of sample performance with $\Delta\text{elpd} = -77.1$ and $\Delta\text{SE}=11.2$, i.e., assuming a $99\%$ $z$-score of $2.576$ we have $\text{CI}_{95\%}[-106;-48]$.

```{r warning=FALSE, message=FALSE}
m_weekly_1 <- brm(
  bf(WQ1_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0
)

pp_check(m_weekly_1,
         type = "bars",
         nsamples = 200)
```

The combinations of our priors are fairly uniform on the outcome space. Let's sample with data now.

#### Sampling and diagnostics

```{r warning=FALSE, message=FALSE}
m_weekly_1 <- brm(
  bf(WQ1_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  # sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0,
  control = list(adapt_delta = 0.99)
)
```

Let's have a look at some diagnostics.

```{r}
# Check divergences, tree depth, energy
rstan::check_hmc_diagnostics(eval(m_weekly_1)$fit)
```

```{r echo=FALSE}
# Check rhat
if(max(bayesplot::rhat(eval(m_weekly_1)), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  message("Rhat:")
  message("Rhat values ok.")
}

# Check neff
if(min(bayesplot::neff_ratio(eval(m_weekly_1)), na.rm = T) <= 0.1) {
  message("Warning: ESS <= 0.1")
} else{
  message("ESS:")
  message("Sufficient ESS.")
}
```

#### Posterior predictive checks

```{r message=FALSE, warning=FALSE, fig.width=9, fig.height=9}
tibble(X     = LETTERS[1:2],
       mu    = c(0, fixef(m_weekly_1)["experiment", 1]),
       sigma = c(1, 1 / (exp(fixef(m_weekly_1)["disc_experiment", 1])))) %>% 
  expand(nesting(X, mu, sigma),
         y = seq(from = -5, to = 5, by = 0.1)) %>% 
  mutate(d = dnorm(y, mu, sigma)) %>% 
  
  ggplot(aes(x = y, y = d, fill = X)) +
  geom_area(alpha = 2/3) +
  geom_vline(xintercept = fixef(m_weekly_1)[1:5, 1], linetype = 3, color = sl[9]) +
  scale_fill_scico_d(palette = "lajolla", begin = .33, end = .67) +
  scale_x_continuous(sec.axis = dup_axis(breaks = fixef(m_weekly_1)[1:5, 1] %>% as.double(), 
                                         labels = parse(text = str_c("theta[", 1:5, "]")))) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Underlying latent scale for our outome Q1, \n given experimental session X", x = NULL) +
  theme_light() +
  theme(axis.ticks.x.top = element_blank(),
        text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
post <- posterior_samples(m_weekly_1)

post <-
  post %>%
  select(`b_Intercept[1]`:`b_Intercept[5]`) %>%
  mutate(iter = 1:n())

means <-
    post %>% 
    summarise_at(vars(`b_Intercept[1]`:`b_Intercept[5]`), mean) %>% 
    pivot_longer(everything(),
                 values_to = "mean")

post %>% 
    gather(name, threshold, -iter) %>% 
    group_by(iter) %>% 
    mutate(theta_bar = mean(threshold)) %>% 
    
    ggplot(aes(x = threshold, y = theta_bar, color = name)) +
    geom_vline(data = means,
               aes(xintercept = mean, color = name),
               linetype = 2) +
    geom_point(alpha = 1/10) +
    scale_color_scico_d(palette = "lajolla", begin = .25) +
    ylab("mean threshold") +
    theme_light() +
    theme(legend.position = "none",
          text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- pp_check(m_weekly_1, type = "ecdf_overlay", nsamples = 50)

p + theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
p <- pp_check(m_weekly_1, type = "bars_grouped", nsamples = 100, 
              group = "experiment") +
  scale_x_continuous("y", breaks = 1:6) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  ggtitle("Data with posterior predictions",
          subtitle = expression(list(italic(N[A])==298, italic(N[B])==158))) +
  theme(legend.background = element_blank(),
        legend.position = c(.9, .75))

my_labels <- as_labeller(c("0" = "A", "1" = "B"))
p + facet_wrap("group", labeller = my_labels) +
  theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
post %>% 
    select(-iter) %>% 
    mutate_all(.funs = ~pnorm(. ,0, 1)) %>% 
    transmute(`p[Y==1]` = `b_Intercept[1]`,
              `p[Y==2]` = `b_Intercept[2]` - `b_Intercept[1]`,
              `p[Y==3]` = `b_Intercept[3]` - `b_Intercept[2]`,
              `p[Y==4]` = `b_Intercept[4]` - `b_Intercept[3]`,
              `p[Y==5]` = `b_Intercept[5]` - `b_Intercept[4]`,
              
              `p[Y==6]` = 1 - `b_Intercept[5]`) %>% 
    set_names(1:6) %>% 
    pivot_longer(everything(), names_to = "Y") %>% 
    
    ggplot(aes(x = value, y = Y)) +
    stat_pointinterval(point_interval = mode_hdi, .width = .95, 
                 fill = sl[4], color = sl[8], size = 1/2, height = 2.5) +
    scale_x_continuous(expression(italic(p)*"["*Y==italic(i)*"]"),
                       breaks = 0:5 / 5,
                       expand = c(0, 0), limits = c(0, 1)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- conditional_effects(m_weekly_1)

plot(p, plot = FALSE)[[2]] +
  xlab("Week number") + 
  ylab("Question 1") +
  scale_x_continuous(breaks= seq(1:12)) +
  scale_y_continuous(breaks= c(3.5, 4, 4.5, 5)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

### WHO-5: Q2 

#### Prior predictive checks

```{r warning=FALSE, message=FALSE}
m_weekly_2 <- brm(
  bf(WQ2_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0
)

pp_check(m_weekly_2,
         type = "bars",
         nsamples = 200)
```

The combinations of our priors are fairly uniform on the outcome space. Let's sample with data now.

#### Sampling and diagnostics

```{r warning=FALSE, message=FALSE}
m_weekly_2 <- brm(
  bf(WQ2_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  # sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0,
  control = list(adapt_delta = 0.99)
)
```

Let's have a look at some diagnostics.

```{r}
# Check divergences, tree depth, energy
rstan::check_hmc_diagnostics(eval(m_weekly_2)$fit)
```

```{r echo=FALSE}
# Check rhat
if(max(bayesplot::rhat(eval(m_weekly_2)), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  message("Rhat:")
  message("Rhat values ok.")
}

# Check neff
if(min(bayesplot::neff_ratio(eval(m_weekly_2)), na.rm = T) <= 0.1) {
  message("Warning: ESS <= 0.1")
} else{
  message("ESS:")
  message("Sufficient ESS.")
}
```

#### Posterior predictive checks

```{r message=FALSE, warning=FALSE, fig.width=9, fig.height=9}
tibble(X     = LETTERS[1:2],
       mu    = c(0, fixef(m_weekly_2)["experiment", 1]),
       sigma = c(1, 1 / (exp(fixef(m_weekly_2)["disc_experiment", 1])))) %>% 
  expand(nesting(X, mu, sigma),
         y = seq(from = -5, to = 5, by = 0.1)) %>% 
  mutate(d = dnorm(y, mu, sigma)) %>% 
  
  ggplot(aes(x = y, y = d, fill = X)) +
  geom_area(alpha = 2/3) +
  geom_vline(xintercept = fixef(m_weekly_2)[1:5, 1], linetype = 3, color = sl[9]) +
  scale_fill_scico_d(palette = "lajolla", begin = .33, end = .67) +
  scale_x_continuous(sec.axis = dup_axis(breaks = fixef(m_weekly_2)[1:5, 1] %>% as.double(), 
                                         labels = parse(text = str_c("theta[", 1:5, "]")))) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Underlying latent scale for our outome Q2, \n given experimental session X", x = NULL) +
  theme_light() +
  theme(axis.ticks.x.top = element_blank(),
        text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
post <- posterior_samples(m_weekly_2)

post <-
  post %>%
  select(`b_Intercept[1]`:`b_Intercept[5]`) %>%
  mutate(iter = 1:n())

means <-
    post %>% 
    summarise_at(vars(`b_Intercept[1]`:`b_Intercept[5]`), mean) %>% 
    pivot_longer(everything(),
                 values_to = "mean")

post %>% 
    gather(name, threshold, -iter) %>% 
    group_by(iter) %>% 
    mutate(theta_bar = mean(threshold)) %>% 
    
    ggplot(aes(x = threshold, y = theta_bar, color = name)) +
    geom_vline(data = means,
               aes(xintercept = mean, color = name),
               linetype = 2) +
    geom_point(alpha = 1/10) +
    scale_color_scico_d(palette = "lajolla", begin = .25) +
    ylab("mean threshold") +
    theme_light() +
    theme(legend.position = "none",
          text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- pp_check(m_weekly_2, type = "ecdf_overlay", nsamples = 50)

p + theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
p <- pp_check(m_weekly_2, type = "bars_grouped", nsamples = 100, 
              group = "experiment") +
  scale_x_continuous("y", breaks = 1:6) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  ggtitle("Data with posterior predictions",
          subtitle = expression(list(italic(N[A])==298, italic(N[B])==158))) +
  theme(legend.background = element_blank(),
        legend.position = c(.9, .75))

my_labels <- as_labeller(c("0" = "A", "1" = "B"))
p + facet_wrap("group", labeller = my_labels) +
  theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
post %>% 
    select(-iter) %>% 
    mutate_all(.funs = ~pnorm(. ,0, 1)) %>% 
    transmute(`p[Y==1]` = `b_Intercept[1]`,
              `p[Y==2]` = `b_Intercept[2]` - `b_Intercept[1]`,
              `p[Y==3]` = `b_Intercept[3]` - `b_Intercept[2]`,
              `p[Y==4]` = `b_Intercept[4]` - `b_Intercept[3]`,
              `p[Y==5]` = `b_Intercept[5]` - `b_Intercept[4]`,
              
              `p[Y==6]` = 1 - `b_Intercept[5]`) %>% 
    set_names(1:6) %>% 
    pivot_longer(everything(), names_to = "Y") %>% 
    
    ggplot(aes(x = value, y = Y)) +
    stat_pointinterval(point_interval = mode_hdi, .width = .95, 
                 fill = sl[4], color = sl[8], size = 1/2, height = 2.5) +
    scale_x_continuous(expression(italic(p)*"["*Y==italic(i)*"]"),
                       breaks = 0:5 / 5,
                       expand = c(0, 0), limits = c(0, 1)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- conditional_effects(m_weekly_2)

plot(p, plot = FALSE)[[2]] +
  xlab("Week number") + 
  ylab("Question 2") +
  scale_x_continuous(breaks= seq(1:12)) +
  scale_y_continuous(breaks= c(3.5, 4, 4.5, 5)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

### WHO-5: Q3 
#### Prior predictive checks

```{r warning=FALSE, message=FALSE}
m_weekly_3 <- brm(
  bf(WQ3_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0
)

pp_check(m_weekly_3,
         type = "bars",
         nsamples = 200)
```

The combinations of our priors are fairly uniform on the outcome space. Let's sample with data now.

#### Sampling and diagnostics

```{r warning=FALSE, message=FALSE}
m_weekly_3 <- brm(
  bf(WQ3_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  # sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0,
  control = list(adapt_delta = 0.99)
)
```

Let's have a look at some diagnostics.

```{r}
# Check divergences, tree depth, energy
rstan::check_hmc_diagnostics(eval(m_weekly_3)$fit)
```

```{r echo=FALSE}
# Check rhat
if(max(bayesplot::rhat(eval(m_weekly_3)), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  message("Rhat:")
  message("Rhat values ok.")
}

# Check neff
if(min(bayesplot::neff_ratio(eval(m_weekly_3)), na.rm = T) <= 0.1) {
  message("Warning: ESS <= 0.1")
} else{
  message("ESS:")
  message("Sufficient ESS.")
}
```

#### Posterior predictive checks

```{r message=FALSE, warning=FALSE, fig.width=9, fig.height=9}
tibble(X     = LETTERS[1:2],
       mu    = c(0, fixef(m_weekly_3)["experiment", 1]),
       sigma = c(1, 1 / (exp(fixef(m_weekly_3)["disc_experiment", 1])))) %>% 
  expand(nesting(X, mu, sigma),
         y = seq(from = -5, to = 5, by = 0.1)) %>% 
  mutate(d = dnorm(y, mu, sigma)) %>% 
  
  ggplot(aes(x = y, y = d, fill = X)) +
  geom_area(alpha = 2/3) +
  geom_vline(xintercept = fixef(m_weekly_3)[1:5, 1], linetype = 3, color = sl[9]) +
  scale_fill_scico_d(palette = "lajolla", begin = .33, end = .67) +
  scale_x_continuous(sec.axis = dup_axis(breaks = fixef(m_weekly_3)[1:5, 1] %>% as.double(), 
                                         labels = parse(text = str_c("theta[", 1:5, "]")))) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Underlying latent scale for our outome Q3, \n given experimental session X", x = NULL) +
  theme_light() +
  theme(axis.ticks.x.top = element_blank(),
        text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
post <- posterior_samples(m_weekly_3)

post <-
  post %>%
  select(`b_Intercept[1]`:`b_Intercept[5]`) %>%
  mutate(iter = 1:n())

means <-
    post %>% 
    summarise_at(vars(`b_Intercept[1]`:`b_Intercept[5]`), mean) %>% 
    pivot_longer(everything(),
                 values_to = "mean")

post %>% 
    gather(name, threshold, -iter) %>% 
    group_by(iter) %>% 
    mutate(theta_bar = mean(threshold)) %>% 
    
    ggplot(aes(x = threshold, y = theta_bar, color = name)) +
    geom_vline(data = means,
               aes(xintercept = mean, color = name),
               linetype = 2) +
    geom_point(alpha = 1/10) +
    scale_color_scico_d(palette = "lajolla", begin = .25) +
    ylab("mean threshold") +
    theme_light() +
    theme(legend.position = "none",
          text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- pp_check(m_weekly_3, type = "ecdf_overlay", nsamples = 50)

p + theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
p <- pp_check(m_weekly_3, type = "bars_grouped", nsamples = 100, 
              group = "experiment") +
  scale_x_continuous("y", breaks = 1:6) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  ggtitle("Data with posterior predictions",
          subtitle = expression(list(italic(N[A])==298, italic(N[B])==158))) +
  theme(legend.background = element_blank(),
        legend.position = c(.9, .75))

my_labels <- as_labeller(c("0" = "A", "1" = "B"))
p + facet_wrap("group", labeller = my_labels) +
  theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
post %>% 
    select(-iter) %>% 
    mutate_all(.funs = ~pnorm(. ,0, 1)) %>% 
    transmute(`p[Y==1]` = `b_Intercept[1]`,
              `p[Y==2]` = `b_Intercept[2]` - `b_Intercept[1]`,
              `p[Y==3]` = `b_Intercept[3]` - `b_Intercept[2]`,
              `p[Y==4]` = `b_Intercept[4]` - `b_Intercept[3]`,
              `p[Y==5]` = `b_Intercept[5]` - `b_Intercept[4]`,
              
              `p[Y==6]` = 1 - `b_Intercept[5]`) %>% 
    set_names(1:6) %>% 
    pivot_longer(everything(), names_to = "Y") %>% 
    
    ggplot(aes(x = value, y = Y)) +
    stat_pointinterval(point_interval = mode_hdi, .width = .95, 
                 fill = sl[4], color = sl[8], size = 1/2, height = 2.5) +
    scale_x_continuous(expression(italic(p)*"["*Y==italic(i)*"]"),
                       breaks = 0:5 / 5,
                       expand = c(0, 0), limits = c(0, 1)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- conditional_effects(m_weekly_3)

plot(p, plot = FALSE)[[2]] +
  xlab("Week number") + 
  ylab("Question 3") +
  scale_x_continuous(breaks= seq(1:12)) +
  scale_y_continuous(breaks= c(3, 3.5, 4, 4.5, 5)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

### WHO-5: Q4 
#### Prior predictive checks

```{r warning=FALSE, message=FALSE}
m_weekly_4 <- brm(
  bf(WQ4_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0
)

pp_check(m_weekly_4,
         type = "bars",
         nsamples = 200)
```

The combinations of our priors are fairly uniform on the outcome space. Let's sample with data now.

#### Sampling and diagnostics

```{r warning=FALSE, message=FALSE}
m_weekly_4 <- brm(
  bf(WQ4_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  # sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0,
  control = list(adapt_delta = 0.99)
)
```

Let's have a look at some diagnostics.

```{r}
# Check divergences, tree depth, energy
rstan::check_hmc_diagnostics(eval(m_weekly_4)$fit)
```

```{r echo=FALSE}
# Check rhat
if(max(bayesplot::rhat(eval(m_weekly_4)), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  message("Rhat:")
  message("Rhat values ok.")
}

# Check neff
if(min(bayesplot::neff_ratio(eval(m_weekly_4)), na.rm = T) <= 0.1) {
  message("Warning: ESS <= 0.1")
} else{
  message("ESS:")
  message("Sufficient ESS.")
}
```

#### Posterior predictive checks

```{r message=FALSE, warning=FALSE, fig.width=9, fig.height=9}
tibble(X     = LETTERS[1:2],
       mu    = c(0, fixef(m_weekly_4)["experiment", 1]),
       sigma = c(1, 1 / (exp(fixef(m_weekly_4)["disc_experiment", 1])))) %>% 
  expand(nesting(X, mu, sigma),
         y = seq(from = -5, to = 5, by = 0.1)) %>% 
  mutate(d = dnorm(y, mu, sigma)) %>% 
  
  ggplot(aes(x = y, y = d, fill = X)) +
  geom_area(alpha = 2/3) +
  geom_vline(xintercept = fixef(m_weekly_4)[1:5, 1], linetype = 3, color = sl[9]) +
  scale_fill_scico_d(palette = "lajolla", begin = .33, end = .67) +
  scale_x_continuous(sec.axis = dup_axis(breaks = fixef(m_weekly_4)[1:5, 1] %>% as.double(), 
                                         labels = parse(text = str_c("theta[", 1:5, "]")))) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Underlying latent scale for our outome Q4, \n given experimental session X", x = NULL) +
  theme_light() +
  theme(axis.ticks.x.top = element_blank(),
        text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
post <- posterior_samples(m_weekly_4)

post <-
  post %>%
  select(`b_Intercept[1]`:`b_Intercept[5]`) %>%
  mutate(iter = 1:n())

means <-
    post %>% 
    summarise_at(vars(`b_Intercept[1]`:`b_Intercept[5]`), mean) %>% 
    pivot_longer(everything(),
                 values_to = "mean")

post %>% 
    gather(name, threshold, -iter) %>% 
    group_by(iter) %>% 
    mutate(theta_bar = mean(threshold)) %>% 
    
    ggplot(aes(x = threshold, y = theta_bar, color = name)) +
    geom_vline(data = means,
               aes(xintercept = mean, color = name),
               linetype = 2) +
    geom_point(alpha = 1/10) +
    scale_color_scico_d(palette = "lajolla", begin = .25) +
    ylab("mean threshold") +
    theme_light() +
    theme(legend.position = "none",
          text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- pp_check(m_weekly_4, type = "ecdf_overlay", nsamples = 50)

p + theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
p <- pp_check(m_weekly_4, type = "bars_grouped", nsamples = 100, 
              group = "experiment") +
  scale_x_continuous("y", breaks = 1:6) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  ggtitle("Data with posterior predictions",
          subtitle = expression(list(italic(N[A])==298, italic(N[B])==158))) +
  theme(legend.background = element_blank(),
        legend.position = c(.9, .75))

my_labels <- as_labeller(c("0" = "A", "1" = "B"))
p + facet_wrap("group", labeller = my_labels) +
  theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
post %>% 
    select(-iter) %>% 
    mutate_all(.funs = ~pnorm(. ,0, 1)) %>% 
    transmute(`p[Y==1]` = `b_Intercept[1]`,
              `p[Y==2]` = `b_Intercept[2]` - `b_Intercept[1]`,
              `p[Y==3]` = `b_Intercept[3]` - `b_Intercept[2]`,
              `p[Y==4]` = `b_Intercept[4]` - `b_Intercept[3]`,
              `p[Y==5]` = `b_Intercept[5]` - `b_Intercept[4]`,
              
              `p[Y==6]` = 1 - `b_Intercept[5]`) %>% 
    set_names(1:6) %>% 
    pivot_longer(everything(), names_to = "Y") %>% 
    
    ggplot(aes(x = value, y = Y)) +
    stat_pointinterval(point_interval = mode_hdi, .width = .95, 
                 fill = sl[4], color = sl[8], size = 1/2, height = 2.5) +
    scale_x_continuous(expression(italic(p)*"["*Y==italic(i)*"]"),
                       breaks = 0:5 / 5,
                       expand = c(0, 0), limits = c(0, 1)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- conditional_effects(m_weekly_4)

plot(p, plot = FALSE)[[2]] +
  xlab("Week number") + 
  ylab("Question 4") +
  scale_x_continuous(breaks= seq(1:12)) +
  scale_y_continuous(breaks= c(3, 3.5, 4, 4.5, 5)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

### WHO-5: Q5 
#### Prior predictive checks

```{r warning=FALSE, message=FALSE}
m_weekly_5 <- brm(
  bf(WQ5_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0
)

pp_check(m_weekly_5,
         type = "bars",
         nsamples = 200)
```

The combinations of our priors are fairly uniform on the outcome space. Let's sample with data now.

#### Sampling and diagnostics

```{r warning=FALSE, message=FALSE}
m_weekly_5 <- brm(
  bf(WQ5_1_6 ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = weekly,
  family = cumulative(probit),
  # sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0,
  control = list(adapt_delta = 0.99)
)
```

Let's have a look at some diagnostics.

```{r}
# Check divergences, tree depth, energy
rstan::check_hmc_diagnostics(eval(m_weekly_5)$fit)
```

```{r echo=FALSE}
# Check rhat
if(max(bayesplot::rhat(eval(m_weekly_5)), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  message("Rhat:")
  message("Rhat values ok.")
}

# Check neff
if(min(bayesplot::neff_ratio(eval(m_weekly_5)), na.rm = T) <= 0.1) {
  message("Warning: ESS <= 0.1")
} else{
  message("ESS:")
  message("Sufficient ESS.")
}
```

#### Posterior predictive checks

```{r message=FALSE, warning=FALSE, fig.width=9, fig.height=9}
tibble(X     = LETTERS[1:2],
       mu    = c(0, fixef(m_weekly_5)["experiment", 1]),
       sigma = c(1, 1 / (exp(fixef(m_weekly_5)["disc_experiment", 1])))) %>% 
  expand(nesting(X, mu, sigma),
         y = seq(from = -5, to = 5, by = 0.1)) %>% 
  mutate(d = dnorm(y, mu, sigma)) %>% 
  
  ggplot(aes(x = y, y = d, fill = X)) +
  geom_area(alpha = 2/3) +
  geom_vline(xintercept = fixef(m_weekly_5)[1:5, 1], linetype = 3, color = sl[9]) +
  scale_fill_scico_d(palette = "lajolla", begin = .33, end = .67) +
  scale_x_continuous(sec.axis = dup_axis(breaks = fixef(m_weekly_5)[1:5, 1] %>% as.double(), 
                                         labels = parse(text = str_c("theta[", 1:5, "]")))) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Underlying latent scale for our outome Q5, \n given experimental session X", x = NULL) +
  theme_light() +
  theme(axis.ticks.x.top = element_blank(),
        text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
post <- posterior_samples(m_weekly_5)

post <-
  post %>%
  select(`b_Intercept[1]`:`b_Intercept[5]`) %>%
  mutate(iter = 1:n())

means <-
    post %>% 
    summarise_at(vars(`b_Intercept[1]`:`b_Intercept[5]`), mean) %>% 
    pivot_longer(everything(),
                 values_to = "mean")

post %>% 
    gather(name, threshold, -iter) %>% 
    group_by(iter) %>% 
    mutate(theta_bar = mean(threshold)) %>% 
    
    ggplot(aes(x = threshold, y = theta_bar, color = name)) +
    geom_vline(data = means,
               aes(xintercept = mean, color = name),
               linetype = 2) +
    geom_point(alpha = 1/10) +
    scale_color_scico_d(palette = "lajolla", begin = .25) +
    ylab("mean threshold") +
    theme_light() +
    theme(legend.position = "none",
          text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- pp_check(m_weekly_5, type = "ecdf_overlay", nsamples = 50)

p + theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
p <- pp_check(m_weekly_5, type = "bars_grouped", nsamples = 100, 
              group = "experiment") +
  scale_x_continuous("y", breaks = 1:6) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  ggtitle("Data with posterior predictions",
          subtitle = expression(list(italic(N[A])==298, italic(N[B])==158))) +
  theme(legend.background = element_blank(),
        legend.position = c(.9, .75))

my_labels <- as_labeller(c("0" = "A", "1" = "B"))
p + facet_wrap("group", labeller = my_labels) +
  theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
post %>% 
    select(-iter) %>% 
    mutate_all(.funs = ~pnorm(. ,0, 1)) %>% 
    transmute(`p[Y==1]` = `b_Intercept[1]`,
              `p[Y==2]` = `b_Intercept[2]` - `b_Intercept[1]`,
              `p[Y==3]` = `b_Intercept[3]` - `b_Intercept[2]`,
              `p[Y==4]` = `b_Intercept[4]` - `b_Intercept[3]`,
              `p[Y==5]` = `b_Intercept[5]` - `b_Intercept[4]`,
              `p[Y==6]` = 1 - `b_Intercept[5]`) %>% 
    set_names(1:6) %>% 
    pivot_longer(everything(), names_to = "Y") %>% 
    
    ggplot(aes(x = value, y = Y)) +
    stat_pointinterval(point_interval = mode_hdi, .width = .95, 
                 fill = sl[4], color = sl[8], size = 1/2, height = 2.5) +
    scale_x_continuous(expression(italic(p)*"["*Y==italic(i)*"]"),
                       breaks = 0:5 / 5,
                       expand = c(0, 0), limits = c(0, 1)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- conditional_effects(m_weekly_5)

plot(p, plot = FALSE)[[2]] +
  xlab("Week number") + 
  ylab("Question 5") +
  scale_x_continuous(breaks= seq(1:12)) +
  scale_y_continuous(breaks= c(3, 3.5, 4, 4.5, 5)) +
  theme_light() +
  theme(text = element_text(size = 20))
```

### Model estimates

```{r, echo = FALSE, warning=FALSE, message=FALSE}
p <- plot(conditional_effects(m_weekly_1), plot=FALSE)
p1 <- p[[2]] +
  ylim(2.75,4.75) +
  ylab("Response") +
  scale_x_continuous(name="", 
                     limits = c(1,12), 
                     breaks = c(1,6,12)) +
  ggtitle("Q1") +
  theme(text = element_text(size=16),
        plot.title = element_text(hjust = 0.5))

p <- plot(conditional_effects(m_weekly_2), plot=FALSE)
p2 <- p[[2]] +
  ylim(2.75,4.75) +
  ylab("") +
  scale_x_continuous(name="", 
                     limits = c(1,12), 
                     breaks = c(1,6,12)) +
  ggtitle("Q2") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size=16),
        plot.title = element_text(hjust = 0.5))

p <- plot(conditional_effects(m_weekly_3), plot=FALSE)
p3 <- p[[2]] +
  ylim(2.75,4.75) +
  ylab("") +
  scale_x_continuous(name="Week", 
                     limits = c(1,12), 
                     breaks = c(1,6,12)) +
  ggtitle("Q3") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size=16),
        plot.title = element_text(hjust = 0.5))

p <- plot(conditional_effects(m_weekly_4), plot=FALSE)
p4 <- p[[2]] +
  ylim(2.75,4.75) +
  ylab("") +
  scale_x_continuous(name="", 
                     limits = c(1,12), 
                     breaks = c(1,6,12)) +
  ggtitle("Q4") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size=16),
        plot.title = element_text(hjust = 0.5))

p <- plot(conditional_effects(m_weekly_5), plot=FALSE)
p5 <- p[[2]] +
  ylim(2.75,4.75) +
  ylab("") +
  scale_x_continuous(name="", 
                     limits = c(1,12), 
                     breaks = c(1,6,12)) +
  ggtitle("Q5") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size=16),
        plot.title = element_text(hjust = 0.5))

(p1 + p2 + p3 + p4 + p5) + 
  plot_layout(nrow = 1)
```

## `daily` data

Recall, the daily data set consists of the following variables,

```{r}
str(daily)
```

where `ID` is the subject, `resp` is the response (Likert $1,\ldots,10$), `experiment` is the session the subject belongs to, and, finally, `Seq` is the order each subject answered the question.

The response, `resp`, when plotted, looks like this,

```{r}
hist(daily$resp, main = "Histogram of responses to daily question")
```

and the maximum and minimum number of responses (days) a subject provided was,

```{r}
max(daily$Seq)
min(daily$Seq)
```

If we take a random sample of $32$ subjects we will see how complicated it will be to analyze this. For the question we have in the daily survey instrument, for each of the $32$ subjects, we've plotted answers (dots) they provided on a $1,\ldots,10$ Likert scale; then we've drawn a linear model for what we've got.

```{r fig.width=9, fig.height=9}
daily |>
  filter(ID %in% sample(x = max(daily$ID), size = 32)) %>%
  ggplot(aes(x = Seq, y = resp)) +
  geom_point() +
  scale_x_continuous(breaks = c(1,20,40,60,80)) +
  scale_y_continuous(breaks = c(1,5,10)) +
  stat_smooth(method = "lm", se = F) +
  ylab("Daily question") +
  xlab("Days") +
  theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20)) +
  facet_wrap( ~ ID, ncol = 4)
```


### Prior predictive checks

We want to model the daily instrument and how it varies over time $t$ (in our case the sequence variable `Seq`). In this case, $t$ will be modeled using a Gaussian Process and then each individual in the dataset will be modeled using a varying intercept (in addition we'll model $\sigma$, called `disc` below, for each experimental session). 

An information theoretical comparison using LOO showed that a model with varying intercepts for each individual had considerably better relative out of sample performance with $\Delta\text{elpd} = -77.1$ and $\Delta\text{SE}=11.2$, i.e., assuming a $99\%$ $z$-score of $2.576$ we have $\text{CI}_{95\%}[-106;-48]$.

```{r warning=FALSE, message=FALSE}
m_daily <- brm(
  bf(resp ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = daily,
  family = cumulative(probit),
  sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0, control = list(adapt_delta=0.95)
)

pp_check(m_daily,
         type = "bars",
         nsamples = 200)
```

The combinations of our priors are fairly uniform on the outcome space. Let's sample with data now.

### Sampling and diagnostics

```{r warning=FALSE, message=FALSE}
m_daily <- brm(
  bf(resp ~ 1 + gp(Seq) + experiment + (1 | ID)) +
    lf(disc ~ 0 + experiment, cmc = FALSE),
  data = daily,
  family = cumulative(probit),
  # sample_prior = "only",
  prior = c(
    prior(normal(0, 2.5), class = Intercept),
    prior(normal(0, 2.5), class = b),
    prior(normal(0, 1), class = b, dpar = disc),
    prior(inv_gamma(4.3, 1), class = lscale, coef = gpSeq),
    prior(weibull(2, 1), class = sdgp),
    prior(weibull(2, 1), class = sd)
  ),
  silent = TRUE, refresh = 0, init = 0,
  control = list(adapt_delta = 0.99, max_treedepth=12)
)
```

Let's have a look at some diagnostics.

```{r}
# Check divergences, tree depth, energy
rstan::check_hmc_diagnostics(eval(m_daily)$fit)
```

```{r echo=FALSE}
# Check rhat
if(max(bayesplot::rhat(eval(m_daily)), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  message("Rhat:")
  message("Rhat values ok.")
}

# Check neff
if(min(bayesplot::neff_ratio(eval(m_daily)), na.rm = T) <= 0.1) {
  message("Warning: ESS <= 0.1")
} else{
  message("ESS:")
  message("Sufficient ESS.")
}
```

### Posterior predictive checks

```{r message=FALSE, warning=FALSE, fig.width=9, fig.height=9}
tibble(X     = LETTERS[1:2],
       mu    = c(0, fixef(m_daily)["experiment", 1]),
       sigma = c(1, 1 / (exp(fixef(m_daily)["disc_experiment", 1])))) %>% 
  expand(nesting(X, mu, sigma),
         y = seq(from = -5, to = 5, by = 0.1)) %>% 
  mutate(d = dnorm(y, mu, sigma)) %>% 
  
  ggplot(aes(x = y, y = d, fill = X)) +
  geom_area(alpha = 2/3) +
  geom_vline(xintercept = fixef(m_daily)[1:9, 1], linetype = 3, color = sl[9]) +
  scale_fill_scico_d(palette = "lajolla", begin = .33, end = .67) +
  scale_x_continuous(sec.axis = dup_axis(breaks = fixef(m_daily)[1:9, 1] %>% as.double(), 
                                         labels = parse(text = str_c("theta[", 1:9, "]")))) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Underlying latent scale for our outome, \n given experimental session X", x = NULL) +
  theme_light() +
  theme(axis.ticks.x.top = element_blank(),
        text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
post <- posterior_samples(m_daily)

post <-
  post %>%
  select(`b_Intercept[1]`:`b_Intercept[9]`) %>%
  mutate(iter = 1:n())

means <-
    post %>% 
    summarise_at(vars(`b_Intercept[1]`:`b_Intercept[9]`), mean) %>% 
    pivot_longer(everything(),
                 values_to = "mean")

post %>% 
    gather(name, threshold, -iter) %>% 
    group_by(iter) %>% 
    mutate(theta_bar = mean(threshold)) %>% 
    
    ggplot(aes(x = threshold, y = theta_bar, color = name)) +
    geom_vline(data = means,
               aes(xintercept = mean, color = name),
               linetype = 2) +
    geom_point(alpha = 1/10) +
    scale_color_scico_d(palette = "lajolla", begin = .25) +
    ylab("mean threshold") +
    theme_light() +
    theme(legend.position = "none",
          text = element_text(size = 20))
```

```{r message=FALSE, warning=FALSE}
p <- pp_check(m_daily, type = "ecdf_overlay", nsamples = 50)

p + theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

```{r}
p <- pp_check(m_daily, type = "bars_grouped", nsamples = 100, 
              group = "experiment") +
  scale_x_continuous("y", breaks = 1:10) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  ggtitle("Data with posterior predictions",
          subtitle = expression(list(italic(N[A])==1024, italic(N[B])==622))) +
  theme(legend.background = element_blank(),
        legend.position = c(.9, .75))

my_labels <- as_labeller(c("0" = "A", "1" = "B"))
p + facet_wrap("group", labeller = my_labels) +
  theme_light() +
  theme(panel.grid = element_blank(),
        text = element_text(size = 20))
```

### Model estimates
```{r}
post %>% 
    select(-iter) %>% 
    mutate_all(.funs = ~pnorm(. ,0, 1)) %>% 
    transmute(`p[Y==1]` = `b_Intercept[1]`,
              `p[Y==2]` = `b_Intercept[2]` - `b_Intercept[1]`,
              `p[Y==3]` = `b_Intercept[3]` - `b_Intercept[2]`,
              `p[Y==4]` = `b_Intercept[4]` - `b_Intercept[3]`,
              `p[Y==5]` = `b_Intercept[5]` - `b_Intercept[4]`,
              `p[Y==6]` = `b_Intercept[6]` - `b_Intercept[5]`,
              `p[Y==7]` = `b_Intercept[7]` - `b_Intercept[6]`,
              `p[Y==8]` = `b_Intercept[8]` - `b_Intercept[7]`,
              `p[Y==9]` = `b_Intercept[9]` - `b_Intercept[8]`,
              `p[Y==10]` = 1 - `b_Intercept[9]`) %>% 
    set_names(1:10) %>% 
    pivot_longer(everything(), names_to = "Y") %>% 
    
    ggplot(aes(x = value, y = Y)) +
    stat_pointinterval(point_interval = mode_hdi, .width = .95, 
                 fill = sl[4], color = sl[8], size = 1/2, height = 2.5) +
    scale_x_continuous(expression(italic(p)*"["*Y==italic(i)*"]"),
                       breaks = 0:5 / 5,
                       expand = c(0, 0), limits = c(0, 1)) +
  scale_y_discrete(limits = factor(seq(1:10))) +
  theme_light() +
  theme(text = element_text(size = 20))
```

```{r, warning=FALSE, message=FALSE}
#pdf("daily.pdf", width=7.5/2.54, height=9.49/2.54)

plot(conditional_effects(m_daily), plot = FALSE)[[2]] +
  xlim(1,84) +
  ylab("Response") +
  scale_x_continuous(name="Day", 
                     limits = c(1,84), 
                     breaks = c(1,seq(10,80, by = 10),84)) +
  scale_y_continuous(name="Response", 
                     limits = c(6,8),
                     breaks = seq(6,8)) +
  theme(text = element_text(size=16))

#dev.off()
```

## Multivariate models with temporal variable

We want a model that uses personal data (e.g., age and gender) as predictors. The idea is to later see if any of the predictors have predictive capacity for the different survey instruments. 

Design models with predictors from `personal` data, together with our indicator `t` for time, `experiment` for experimental session, and a varying intercept `ID` that varies depending on subject.

### Prior and posterior predictive checks

Let's now sample all models with the same predictors we used above (visual prior and posterior predictive checks were done for each model).

```{r m-maas, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# MAAS
#
################################################################################
bf1 <- bf(mvbind(MAASQ1_1_6,
                 MAASQ2_1_6,
                 MAASQ3_1_6,
                 MAASQ4_1_6,
                 MAASQ5_1_6,
                 MAASQ6_1_6,
                 MAASQ7_1_6,
                 MAASQ8_1_6,
                 MAASQ9_1_6,
                 MAASQ10_1_6,
                 MAASQ11_1_6,
                 MAASQ12_1_6,
                 MAASQ13_1_6,
                 MAASQ14_1_6,
                 MAASQ15_1_6) ~ 
            1 + Age + Gender_0_1 + Occupation_0_1 + Living_1_4 + t + (1 |e| Experiment_1_2) + (1 |c| ID))

# Prior predictive checks have been conducted and the probability mass 
# is distributed evenly on the outcome space
p <- get_prior(bf1, data=d, family=cumulative(probit)) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_maas <- brm(bf1,
    family = cumulative(probit),
    data = d,
    prior = p,
    #sample_prior = "only", # use if you only want to sample from prior
    silent = TRUE,
    iter = 5e3,
    inits = "0",
    control = list(adapt_delta=0.99),
    refresh = 0)

# use the below to do prior and posterior predictive checks
# change resp to the response variable you want to check 
pp_check(m_maas, resp = "MAASQ116", type = "bars", nsamples = 250) 
```

```{r m-spane, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# SPANE
#
################################################################################

bf1 <- bf(mvbind(SPANEQ1_1_5,
                 SPANEQ2_1_5,
                 SPANEQ3_1_5,
                 SPANEQ4_1_5,
                 SPANEQ5_1_5,
                 SPANEQ6_1_5,
                 SPANEQ7_1_5,
                 SPANEQ8_1_5,
                 SPANEQ9_1_5,
                 SPANEQ10_1_5,
                 SPANEQ11_1_5,
                 SPANEQ12_1_5) ~ 
            1 + Age + Gender_0_1 + Occupation_0_1 + Living_1_4 + t + (1 |e| Experiment_1_2) + (1 |c| ID))

p <- get_prior(bf1, data=d, family=cumulative(probit)) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_spane <- brm(bf1,
    family = cumulative(probit),
    data = d,
    prior = p,
    init = "0",
    iter = 5e3,
    control = list(adapt_delta=0.99),
    # sample_prior = "only", # use if you only want to sample from prior
    silent = TRUE,
    refresh = 0)

# use the below to do prior and posterior predictive checks
# change resp to the response variable you want to check 
# pp_check(m_spane, resp = "SPANEQ115", type = "bars", nsamples = 250) 
```

```{r m-pwb, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# PWB
#
################################################################################

bf1 <- bf(mvbind(PWBQ1_1_7,
                 PWBQ2_1_7,
                 PWBQ3_1_7,
                 PWBQ4_1_7,
                 PWBQ5_1_7,
                 PWBQ6_1_7,
                 PWBQ7_1_7,
                 PWBQ8_1_7) ~ 
            1 + Age + Gender_0_1 + Occupation_0_1 + Living_1_4 + t + (1 |e| Experiment_1_2) + (1 |c| ID))

p <- get_prior(bf1, data=d, family=cumulative(probit)) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_pwb <- brm(bf1,
    family = cumulative(probit),
    data = d,
    prior = p,
    init = "0",
    control = list(adapt_delta=0.95),
    iter = 5e3,
    # sample_prior = "only", # use if you only want to sample from prior
    silent = TRUE,
    refresh = 0)

# pp_check(m_pwb, resp = "PWBQ117", type = "bars", nsamples = 250) 
```

```{r m-pst, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# PST
#
################################################################################
# Here we move to a bernoulli since we have 0/1 outcome
bf1 <- bf(mvbind(PSTQ1_0_1,
                 PSTQ2_0_1,
                 PSTQ3_0_1,
                 PSTQ4_0_1,
                 PSTQ5_0_1,
                 PSTQ6_0_1,
                 PSTQ7_0_1,
                 PSTQ8_0_1,
                 PSTQ9_0_1,
                 PSTQ10_0_1,
                 PSTQ11_0_1,
                 PSTQ12_0_1,
                 PSTQ13_0_1,
                 PSTQ14_0_1,
                 PSTQ15_0_1,
                 PSTQ16_0_1,
                 PSTQ17_0_1,
                 PSTQ18_0_1,
                 PSTQ19_0_1,
                 PSTQ20_0_1,
                 PSTQ21_0_1,
                 PSTQ22_0_1) ~ 
            1 + Age + Gender_0_1 + Occupation_0_1 + Living_1_4 + t + (1 |e| Experiment_1_2) + (1 |c| ID))

p <- get_prior(bf1, data=d, family=bernoulli) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_pst <- brm(bf1,
    family = bernoulli,
    data = d,
    prior = p,
    # sample_prior = "only",
    silent = TRUE,
    refresh = 0
    )

# pp_check(m_pst, resp = "PSTQ101", type = "bars", nsamples = 250) 
```

```{r m-se, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# SE - two models (Cumulative and Bernoulli), both multivariate 
#
################################################################################
# NOTE: the first two questions can be analyzed as Bernoulli 
bf1 <- bf(mvbind(SEQ1_1_4, # this and the next outcome only has two categories
                 SEQ2_1_4,
                 SEQ3_1_4,
                 SEQ4_1_4,
                 SEQ5_1_4,
                 SEQ6_1_4,
                 SEQ7_1_4,
                 SEQ8_1_4,
                 SEQ9_1_4,
                 SEQ10_1_4) ~
            1 + Age + Gender_0_1 + Occupation_0_1 + Living_1_4 + t + (1 |e| Experiment_1_2) + (1 |c| ID))

p <- get_prior(bf1, data=d, family=cumulative(probit)) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_se <- brm(bf1,
    family = cumulative(probit),
    data = d,
    prior = p,
    init = "0",
    control = list(adapt_delta = 0.99),
    iter = 5e3,
    # sample_prior = "only",
    silent = TRUE,
    refresh = 0)

# pp_check(m_se, resp = "SEQ314", type = "bars", nsamples = 250) 

```

```{r m-pph, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# PPHQ
#
################################################################################

bf1 <- bf(mvbind(PPHQ1_1_5,
                 PPHQ2_1_5,
                 PPHQ3_1_5,
                 PPHQ4_1_5,
                 PPHQ5_1_5,
                 PPHQ6_1_5,
                 PPHQ7_1_5,
                 PPRQ1_1_10,
                 PPRQ2_1_10,
                 PPRQ3_1_10,
                 PPOQ1_1_7
                 ) ~ 
            1 + Age + Gender_0_1 + Occupation_0_1 + Living_1_4 + t + (1 |e| Experiment_1_2) + (1 |c| ID))

p <- get_prior(bf1, data=d, family=cumulative(probit)) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_pph <- brm(bf1,
    family = cumulative(probit),
    data = d,
    prior = p,
    init = "0",
    iter = 1e4,
    control =list(adapt_delta=0.96),
    # sample_prior = "only",
    silent = TRUE,
    refresh = 0)

# pp_check(m_pph, resp = "PPHQ115", type = "bars", nsamples = 250) 
```

So we have now sampled a number of models ($6$), i.e., for each instrument we have one multivariate model ($>1$ outcome), where we also estimate the correlation between the outcome given the subject's ID. 

Before we put any trust in these models we need to check a number of diagnostics.

### Diagnostics

First, we check general HMC diagnostics. Second, we check that $\widehat{R} \leq 1.01$.

```{r diagnostics, echo = FALSE}
# ugly as shit but there's a bug in R's lazyLoadDBinsertVariable 
# so eval w/ for loop doesn't work...

# Check divergences, tree depth, energy, and rhat  
# for each model
rstan::check_hmc_diagnostics(m_maas$fit)
if (max(bayesplot::rhat(m_maas), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  cat("Rhat:\n")
  message("Rhat values ok.")
}

rstan::check_hmc_diagnostics(m_spane$fit)
if (max(bayesplot::rhat(m_spane), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  cat("Rhat:\n")
  message("Rhat values ok.")
}

rstan::check_hmc_diagnostics(m_pwb$fit)
if (max(bayesplot::rhat(m_pwb), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  cat("Rhat:\n")
  message("Rhat values ok.")
}

rstan::check_hmc_diagnostics(m_pst$fit)
if (max(bayesplot::rhat(m_pst), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  cat("Rhat:\n")
  message("Rhat values ok.")
}

rstan::check_hmc_diagnostics(m_se$fit)
if (max(bayesplot::rhat(m_se), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  cat("Rhat:\n")
  message("Rhat values ok.")
}

rstan::check_hmc_diagnostics(m_pph$fit)
if (max(bayesplot::rhat(m_pph), na.rm = T) >= 1.01) {
  message("Warning: Rhat >= 1.01")
} else {
  cat("Rhat:\n")
  message("Rhat values ok.")
}
```


Hamiltonian Monte Carlo diagnostics indicate all is well (we've also checked traceplots, effective sample sizes, and other diagnostics for all models).

### Parameter estimates

First, let's summarize what we have so far:

1. Weekly trends modeled with Gaussian Process.
2. Daily trend modeled with Gaussian Process. 
3. Six multivariate models with the temporal variable to analyze entry/exit. 

We can now investigate which, if any, parameters are significant on the 95%-level for the third item in the list, i.e., for each model, and each question, plot all parameters. Any parameters that are significant on the 95%-level could warrant further analysis, and in particular a connection to the qualitative analysis.

For each model we first analyze the temporal variable $t$. Then we analyze the rest of the $\beta$ parameters. Finally, where appropriate we look at the conditional effects. All densities we plot are limited to 95% probability mass, while the 50% probability mass is shaded around a vertical line, which is the median.

```{r class.source="bg-danger", class.output="bg-warning", eval=FALSE}
In short, any density that does not cross zero (the vertical line) is an effect of interest.
```

Each of the following models used a sample size of $n=$ `r nrow(m_maas$data)` for sampling.

#### Mindful attention awareness scale (MAAS)

The model estimated `r length(brms::parnames(m_maas))` parameters.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_maas, regex_pars = "_t$", prob = 0.5, prob_outer = 0.95) +
  scale_y_discrete(limits=rev, labels = seq(15,1)) +
  ggtitle(expression(paste("Temporal variable ", italic(t), " listed according to MAAS questions")))
```

For Questions $1$--$8$, $11$--$12$, and $14$ the parameter $t$ is negative. In short, the respondents answered with lower responses at $t_1$ than at $t_0$ for these questions.

The questions were phrased in the following way:

* Q1 "I could be experiencing some emotion and not be conscious of it until some time later."
* Q2 "I break or spill things because of carelessness, not paying attention, or thinking of something else."
* Q3 "I find it difficult to stay focused on what's happening in the present."
* Q8 "I rush through activities without being really attentive to them."
* Q14 "I find myself doing things without paying attention."

If we look at each unique parameter, in each question, can we see which, if any, predictors drove these results?

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_maas, prob = 0.5, prob_outer = 0.95, regex_pars = "Age$")
```

Much variance makes the estimates uncertain and, ultimately, no parameter is significant.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_maas, prob = 0.5, prob_outer = 0.95, regex_pars = "Gender_0_1$")
```

And the same applies to gender. How about occupation status?

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_maas, prob = 0.5, prob_outer = 0.95, regex_pars = "Occupation_0_1$")
```

Occupation status (student/non-student) has an effect for Q2. Let's look at living conditions before we turn our attention to the next instrument.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
mcmc_areas(m_maas, prob = 0.5, prob_outer = 0.95, regex_pars = c("Living_1_4"))
```

Questions $1$--$3$ are significant, as are Q$8$, and Q$12$.

#### Scale of positive and negative experience (SPANE)

The model estimated `r length(brms::parnames(m_spane))` parameters.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_spane, regex_pars = "_t$", prob = 0.5, prob_outer = 0.95) +
  scale_y_discrete(limits=rev, labels = seq(12,1)) +
  ggtitle(expression(paste("Temporal variable ", italic(t), " listed according to SPANE questions")))
```

All $t$ parameters are significant (either negative or positive). If a parameter is positive (i.e., to the right of zero), then subjects responded with higher values at $t_1$. 

#### Personal well-being index (PWB)

The model estimated `r length(brms::parnames(m_pwb))` parameters.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_pwb, regex_pars = "_t$", prob = 0.5, prob_outer = 0.95) +
  scale_y_discrete(limits=rev, labels = seq(8,1)) +
  ggtitle(expression(paste("Temporal variable ", italic(t), " listed according to PWB questions")))
```

All $t$ parameters are significant, i.e., higher values at $t_1$, except for Q$3$.

#### Positive thinking (PST)

The model estimated `r length(brms::parnames(m_pst))` parameters.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_pst, regex_pars = "_t$", prob = 0.5, prob_outer = 0.95) +
  scale_y_discrete(limits=rev, labels = seq(22,1)) +
  ggtitle(expression(paste("Temporal variable ", italic(t), " listed according to PST questions")))
```

Questions $4$, $9$, $12$, $15$, $17$--$18$ are significant.

####  Self efficacy (SE)

The model estimated `r length(brms::parnames(m_se))` parameters.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_se, regex_pars = "_t$", prob = 0.5, prob_outer = 0.95) +
  scale_y_discrete(limits=rev, labels = seq(10,1)) +
  ggtitle(expression(paste("Temporal variable ", italic(t), " listed according to SE questions")))
```

Questions $6$, $7$, and $9$ are significant.

#### Perceived productivity (PP)

The model estimated `r length(brms::parnames(m_pph))` parameters.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_pph, regex_pars = "_t$", prob = 0.5, prob_outer = 0.95) +
  scale_y_discrete(limits=rev, labels = seq(11,1)) +
  ggtitle(expression(paste("Temporal variable ", italic(t), " listed according to PP questions")))
```

Question1 $1$ shows a significant difference when moving from $t_0$ to $t_1$ (lower responses at $t_1$). 

Let's examine the parameters for this question.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(m_pph, prob = 0.5, prob_outer = 0.95,
           regex_pars = c("^b_PPHQ115_[A-H]",
                          "^b_PPHQ115_[J-Z]")) + 
  ggtitle("Question 1")
```

The predictor `gender` has a negative effect (albeit not significant).

# (APPENDIX) Appendices {-} 

# Assumptions concerning the data-generation process {#appA}

In order to design an appropriate model, one of the things we need to make assumptions about is the underlying data-generative model, i.e., a prior for the data we have, which is usually called the likelihood. 

In short, there are four candidates: Cumulative, Continuation ratio, Stopping ratio, and Adjacent category. Let's use LOO to create identical null models with default priors, and then use the same data for all models to compare them from an information theoretical perspective.

```{r likelihoods, echo=TRUE, warning=FALSE, message=FALSE}
bf1 <- bf(mvbind(MAASQ1_1_6,
                 MAASQ2_1_6,
                 MAASQ3_1_6,
                 MAASQ4_1_6,
                 MAASQ5_1_6,
                 MAASQ6_1_6,
                 MAASQ7_1_6,
                 MAASQ8_1_6,
                 MAASQ9_1_6,
                 MAASQ10_1_6,
                 MAASQ11_1_6,
                 MAASQ12_1_6,
                 MAASQ13_1_6,
                 MAASQ14_1_6,
                 MAASQ15_1_6) ~ 
            1)

m0 <- brm(bf1,
    family = cumulative,
    data = d,
    silent = TRUE,
    refresh = 0
    )

mcr <- brm(bf1,
    family = cratio,
    data = d,
    silent = TRUE,
    refresh = 0
    )

msr <- brm(bf1,
    family = sratio,
    data = d,
    silent = TRUE,
    refresh = 0
    )

mac <- brm(bf1,
    family = acat,
    data = d,
    silent = TRUE,
    refresh = 0
    )

m0 <- add_criterion(m0, criterion = "loo")
msr <- add_criterion(msr, criterion = "loo")
mcr <- add_criterion(mcr, criterion = "loo")
mac <- add_criterion(mac, criterion = "loo")

# setting moment_match = TRUE will still lead to the same conclusion
loo_compare(m0, mcr, msr, mac)
```

Evidently, since $\Delta$SE is fairly large, in comparison to the relative difference in expected log pointwise predictive density ($\Delta$elpd), we can safely assume that there's no significant difference between the likelihoods and, thus, opt for the standard approach, i.e., the Cumulative distribution, in this case represented by $\mathcal{M}_0$.


# Computational environment

```{r}
print(sessionInfo(), locale=FALSE)
```
