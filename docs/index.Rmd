---
title: "Rise 2 Flow"
author: "B. Penzenstadler & R. Torkar"
date: "First version: 2020-12-26. Current version: `r Sys.time()`."
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    scroll_highlight: yes
    number_sections: true
bibliography: references.bib
csl: elsevier-harvard.csl
link-citations: true
linkcolor: blue
---

```{r setup, include=FALSE}
start.time <- Sys.time()
knitr::opts_chunk$set(cache = TRUE)
```

```{r setup2, echo=FALSE, message=FALSE}
library("brms") 
library("plyr") # rm non-duplicates
library("tidyverse") 
library("bayesplot")
library("ggplot2")
library("ggthemes")
library("patchwork") 
library("openxlsx")
library("data.table")
library("here") # make sure Rmd and Rproj root is the same
rstan::rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

# Introduction
The Rise 2 Flow study used a number of instruments during the entry, exit, and weekly sessions (additionally personal data was collected during the entry session).

For entry and exit sessions six instruments were used:

* Mindful attention awareness scale (MAAS).^[https://ppc.sas.upenn.edu/resources/questionnaires-researchers/mindful-attention-awareness-scale]
* Scale of positive and negative experience (SPANE).^[https://www.midss.org/content/scale-positive-and-negative-experience-spane-0]
* Personal wellbeing index (PWB).^[http://www.acqol.com.au/instruments]
* Positive thinking (PST).^[https://www.psytoolkit.org/survey-library/pts.html]
* Self efficacy (SE).^[https://sparqtools.org/mobility-measure/new-general-self-efficacy-scale/]
* Perceived productivity (PP).^[https://www.hcp.med.harvard.edu/hpq/info.php]

In addition, a seventh instrument, mini-IPIP, was added to the exit session to control for personality type.^[https://ipip.ori.org/MiniIPIPKey.htm]

For the weekly sessions the WHO-5 well-being index was used (WHO-5).^[https://www.psykiatri-regionh.dk/who-5/who-5-questionnaires/Pages/default.aspx]

To summarize, the study was executed according to,

1. An entry survey, at time $t_0$
2. A weekly survey, at time $t_{{t_0 + 1}}, \ldots, t_{{t_0+13}}$
3. An exit survey, at time $t_{0+11}$

The main question the study tries to answer is: **Is there a difference in the responses (i.e., higher/lower values on responses), across all or among some instruments, over time?**

In order to answer that question we can first of all compare outcomes of $t_0$ and $t_1$, and contrast with personal data, e.g., age, gender, IPIP. Next, the weekly session can be used to investigate the trend over time, and perhaps see where a noticeable effect, if it exists, shows up.

# Data cleaning

First we load all five datasets. For each dataset, make sure we set correct variable types.

```{r load, echo=TRUE}
entry <- read.xlsx(here("data/R2F Quant Comp Data Entry.xlsx"))
exit <- read.xlsx(here("data/R2F Quant Comp Data Exit.xlsx"))
weekly <- read.xlsx(here("data/R2F Quant Weekly.xlsx"), detectDates = T)
ipip <- read.xlsx(here("data/R2F IPIP.xlsx"))
pers <- read.xlsx(here("data/R2F Pers Data.xlsx")) # personal data
daily <- read.xlsx(here("data/R2F Daily.xlsx"), detectDates = T) # yes, also daily data
```

## `entry` and `exit` datasets

We need to set a number of columns as factors (ordered factors in many cases). Additionally, when we have Yes/No answers, as we do in some questions below, we set them to 0/1 since they will be modeled with a Bernoulli likelihood.

First we clean the `entry` dataset.

```{r clean-entry, echo=TRUE, warning=FALSE}
for(j in 3:17){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("Almost never", "Very infrequently", "Somewhat infrequently", "Somewhat frequently", "Very frequently", "Almost always"), ordered = TRUE))
}

for(j in 18:29){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("Very rarely or never", "Rarely", "Sometimes", "Often", "Very often or always"), ordered = TRUE))
}

for(j in 30:37){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("Strongly disagree", "Disagree", "Slightly disagree", "Mixed or neither agree nor disagree", "Slightly agree", "Agree", "Strongly agree"), ordered = TRUE))
}

for(i in 38:59)
  entry[,eval(i)] <- ifelse(entry[eval(i)] == 'Yes', 1, 0)

for(j in 60:69){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("Hardly true","Rather true","Exactly true"), ordered = TRUE))
}

for(j in 70:76){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("None of the time","A little of the time","Some of the time","Most of the time","All of the time"), ordered = TRUE))
}

for(j in 77:79){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("1","2","3","4","5","6","7","8","9","10"), ordered = TRUE))
}

for(j in 80:80){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("You were a lot worse than other workers","You were a little worse than other workers","You were somewhat worse than other workers","You were about average","You were somewhat better than other workers","You were a little better than other workers","You were a lot better than other workers"), ordered = TRUE))
}
```

Next, we clean the `exit` dataset, which consists of the same variables as above.

```{r clean-exit, echo=TRUE, warning=FALSE}
for(j in 3:17){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("Almost never", "Very infrequently", "Somewhat infrequently", "Somewhat frequently", "Very frequently", "Almost always"), ordered = TRUE))
}

for(j in 18:29){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("Very rarely or never", "Rarely", "Sometimes", "Often", "Very often or always"), ordered = TRUE))
}

for(j in 30:37){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("Strongly disagree", "Disagree", "Slightly disagree", "Mixed or neither agree nor disagree", "Slightly agree", "Agree", "Strongly agree"), ordered = TRUE))
}

for(i in 38:59)
  exit[,eval(i)] <- ifelse(exit[eval(i)] == 'Yes', 1, 0)


for(j in 60:69){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("Hardly true","Rather true","Exactly true"), ordered = TRUE))
}

for(j in 70:76){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("None of the time","A little of the time","Some of the time","Most of the time","All of the time"), ordered = TRUE))
}

for(j in 77:79){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("1","2","3","4","5","6","7","8","9","10"), ordered = TRUE))
}

for(j in 80:80){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("You were a lot worse than other workers","You were a little worse than other workers","You were somewhat worse than other workers","You were about average","You were somewhat better than other workers","You were a little better than other workers","You were a lot better than other workers"), ordered = TRUE))
}
```

## `weekly` dataset

The `weekly` dataset contains five columns of the same type, which we set as ordered categorical.

```{r clean-weekly, warnings = FALSE, echo = TRUE}
for(j in 4:8){
  set(weekly, i=NULL, j=j, value=factor(weekly[[j]], levels = c("At no time", "Less than half of the time", "Some of the time", "More than half of the time",  "Most of the time", "All of the time"), ordered = TRUE))
}
```

## `ipip` dataset

The mini-IPIP instrument uses only five levels for all 20 questions (ordered categorical).

```{r clean-ipip, warnings = FALSE, echo = TRUE}
for(j in 3:22){
  set(ipip, i=NULL, j=j, value=factor(ipip[[j]], levels = c("Disagree", "Somewhat disagree", "Neither agree nor disagree", "Somewhat agree", "Agree"), ordered = TRUE))
}
```

## `pers` dataset

In the `pers` dataset we have a mix of variable types we need to deal with. `Age` should be scaled, `Gender` and `Occupation` set to 1/2, and `Living conditions` set to factors (unordered).

```{r clean-pers, warnings = FALSE, echo = TRUE}
# convert Age to numeric and standardize (note we have two NAs, so we suppress the warning we get)
suppressWarnings(pers$Age <- scale(as.numeric(pers$Age)))

# set 1/2 as indicators for gender
pers$Gender_0_1 <- ifelse(pers$Gender_0_1 == "Man/Transman", 1, 2)

# many categories exist for occupation, but let's simplify this so we can 
# use this variable for something. Indicate if they are students or not.
pers$Occupation <- ifelse(pers$Occupation == "Student", 1, 2)

# make living condition a categorical factor (unordered)
pers$Living_1_4 <- factor(pers$Living_1_4, levels = c("I live by myself", "I live in shared housing", "I live with a partner", "I live with my family"))

# remove the last three columns since we have >64% NAs
pers[,7:9] <- NULL
```

## Missingness analysis

Check how many cells are NA.

```{r missingness, echo=TRUE}
table(is.na(entry))
table(is.na(exit))
table(is.na(weekly))
table(is.na(pers))
```

Clearly we have missing data here, but it's only a few percentages ($0.6$--$1.8$%). Let's use complete case analysis for now (i.e., remove all rows containing NAs). Later, if needed, we can model the missingness in a principled Bayesian way.

```{r rm-NAs, echo=TRUE}
entry <- entry[complete.cases(entry), ]
exit <- exit[complete.cases(exit), ]
weekly <- weekly[complete.cases(weekly), ]
pers <- pers[complete.cases(pers), ]
```

Remember, the main question the study tries to answer is: **Is there a difference in the responses (i.e., higher/lower values on responses), across all or among some instruments, over time?** This means that for now we can discard of the weekly data and instead focus on the entry and exit instruments, together with personal data (i.e., age, gender, occupation, and living conditions).

In order for us to conduct inferences along this line of thinking, we will make use of dummy variable regression estimators (DVRE), which is numerically identical to deviation score estimators. The DVRE approach dummy encodes our time variable $t$ and sets an index $0/1$, where $t_0 = 0$ and $t_1 = 1$. In short, each subject (`ID`) will have two rows where one row is the entry instrument $t = 0$, and one row has the exit instrument $t = 1$. We'll create six datasets which are divided according to each instrument we use as outcome (MAAS, SPANE, PWB, PST, SE, and PP), and then see if our predictors are useful for predicting the outcome (i.e., is there a significant difference in the $\beta$ estimators) and then also investigate if the outcome at $t_0$ equals $t_1$ (and if they aren't the same, how much do they differ?)

```{r split_join, echo=TRUE}
# create new column t, and set to 0 or 1
entry$t <- 0
exit$t <- 1

# Remove all suffixes in both files so we have the same column names
colnames(entry) <- gsub('_en', '', colnames(entry))
colnames(exit) <- gsub('_ex', '', colnames(exit))

# also remove all dashes and underscores in column names
colnames(entry) <- gsub('_', '', colnames(entry))
colnames(exit) <- gsub('_', '', colnames(exit))
colnames(entry) <- gsub('-', '', colnames(entry))
colnames(exit) <- gsub('-', '', colnames(exit))
colnames(ipip) <- gsub('_', '', colnames(ipip))
colnames(pers) <- gsub('_', '', colnames(pers))
colnames(ipip) <- gsub('-', '', colnames(ipip))
colnames(pers) <- gsub('-', '', colnames(pers))

# add rows of entry and exit
d <- rbind(entry, exit)

# keep only rows if they show up twice, so we have a within-measurement of each # individual at time t_0 and t_1
d <- ddply(d, .(ID), function(x){
    if(nrow(x)==1){
        return(NULL)
    }
    else{
        return(x)
    }
})

table(d$t)
```

We have $13$ individuals with entry and exit surveys completely filled out. Let's also add the `ipip` and `pers` datasets, and then use only individuals with complete data.

```{r, echo = TRUE}
d <- inner_join(d, pers, by = "ID")
d <- inner_join(d, ipip, by = "ID")
```

After joining these two datasets we have `r length(table(d$ID))` subjects in the dataset.

# Model designs

## Data-generation assumption

Next, in order to design an appropriate model, one of the things we need to make assumptions about is the underlying data-generative model, i.e., what model generated the type of data we have at our disposal. In short, there are four candidates: Cumulative, Continuation ratio, Stopping ratio, and Adjacent category. Above we opted for a default `Cumulative`. Let's instead use LOO to create identical models and then use the same data for all models to compare them from an information theoretical perspective.

```{r likelihoods, echo=TRUE, warning=FALSE, message=FALSE}
bf1 <- bf(mvbind(MAASQ116,
                 MAASQ216,
                 MAASQ316,
                 MAASQ416,
                 MAASQ516,
                 MAASQ616,
                 MAASQ716,
                 MAASQ816,
                 MAASQ916,
                 MAASQ1016,
                 MAASQ1116,
                 MAASQ1216,
                 MAASQ1316,
                 MAASQ1416,
                 MAASQ1516) ~ 
            1 )

m0 <- brm(bf1,
    family = cumulative,
    data = d,
    silent = TRUE,
    refresh = 0
    )

mcr <- brm(bf1,
    family = cratio,
    data = d,
    silent = TRUE,
    refresh = 0
    )
msr <- brm(bf1,
    family = sratio,
    data = d,
    silent = TRUE,
    refresh = 0
    )
mac <- brm(bf1,
    family = acat,
    data = d,
    silent = TRUE,
    refresh = 0
    )

m0 <- add_criterion(m0, criterion = "loo")
msr <- add_criterion(msr, criterion = "loo")
mcr <- add_criterion(mcr, criterion = "loo")
mac <- add_criterion(mac, criterion = "loo")

loo_compare(m0, mcr, msr, mac)
```

Evidently, since $\Delta$SE is fairly large, in comparison to the relative difference in expected log pointwise predictive density ($\Delta$elpd), we can safely assume that there's no significant difference between the likelihoods and, thus, opt for the standard approach, i.e., the Cumulative distribution, in this case represented by $\mathcal{M}_0$.

## `weekly` data {#weekly}

### Prior and posterior predictive checks

We want to model the weekly instrument and how it varies over time $t$. In this case, $t$ will be modeled using a Gaussian Process and then each individual in the dataset will be modeled using a varying intercept.

```{r, warning=FALSE, message=FALSE}
weekly <- left_join(weekly, pers, by = "ID")

# make sure ID is a factor
weekly$ID <- as.factor(weekly$ID)

# Need to format data so that each person's measurements goes 
# from 1 ... n, according to order, then we use those numbers as temporal var
weekly <- weekly[order(weekly$ID),]
weekly$Seq <- sequence(tabulate(weekly$ID))
```

```{r, warning=FALSE, message=FALSE}

# Pick first question. We could model this as multivariate but it won't give us 
# anything extra
p <- get_prior(WQ1_1_6 ~ gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID), 
               data = weekly,
               family = cumulative())

p$prior[1] <- "normal(0,2)"
p$prior[8] <- "normal(0,5)"
p$prior[13] <- ""
p$prior[14] <- "inv_gamma(1.6, 0.1)"
p$prior[15] <- "weibull(2,1)"

WQ1gp <- brm(WQ1_1_6 ~ gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID), 
             data = weekly,
             family = cumulative(), 
             prior = p, 
             sample_prior = "only",
             silent = TRUE, 
             refresh = 0)

pp_check(WQ1gp, type="bars", nsamples = 100)
```

The priors are fairly uniform on the outcome space. Let's sample with data now.

```{r weekly-1, warning=FALSE, message=FALSE}
WQ1gp <- brm(WQ1_1_6 ~ gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID), 
             data = weekly,
             family = cumulative(), 
             prior = p, 
             control = list(adapt_delta = 0.999, max_treedepth = 13),
             silent = TRUE, 
             refresh = 0)
```

```{r weekly-2, warning=FALSE, message=FALSE}
WQ2gp <- brm(WQ2_1_6 ~ gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID), 
             data = weekly,
             family = cumulative(), 
             prior = p, 
             control = list(adapt_delta = 0.99),
             silent = TRUE, 
             refresh = 0)
```

```{r weekly-3, warning=FALSE, message=FALSE}
WQ3gp <- brm(WQ3_1_6 ~ gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID), 
             data = weekly,
             family = cumulative(), 
             prior = p, 
             control = list(adapt_delta = 0.999),
             silent = TRUE, 
             refresh = 0)
```

```{r weekly-4, warning=FALSE, message=FALSE}
WQ4gp <- brm(WQ4_1_6 ~ gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID), 
             data = weekly,
             family = cumulative(), 
             prior = p, 
             control = list(adapt_delta = 0.999),
             silent = TRUE, 
             refresh = 0)
```

```{r weekly-5, warning=FALSE, message=FALSE}
WQ5gp <- brm(WQ5_1_6 ~ gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID),
             data = weekly,
             family = cumulative(), 
             prior = p, 
             control = list(adapt_delta = 0.95),
             silent = TRUE, 
             refresh = 0)
```

### Diagnostics

```{r}
rstan::check_hmc_diagnostics(m_daily$fit)

# check rhat and ESS
if(max(rhat(eval(m_daily)), na.rm=T) >= 1.01) {
  print("Warning: Rhat >=1.01")
} else {
  print("All Rhat <1.01")
}

if(min(neff_ratio(eval(m_daily)), na.rm=T) <= 0.2) {
  print("Warning: ESS <=0.2")
} else {
  print("All ESS >0.2")
}
```

### Parameter estimates

```{r, warning=FALSE, message=FALSE}
# Set the same y axis on all plots

p1 <- plot(conditional_effects(WQ1gp), plot = FALSE)[[5]] + 
  ylim(1,5) + ggtitle("Q1") + ylab("") + xlab("") +
  theme_tufte() +
  theme(
    axis.text.x = element_blank(), 
    axis.ticks.x = element_blank()
  )

p2 <- plot(conditional_effects(WQ2gp), plot = FALSE)[[5]] + 
  ylim(1,5) + ggtitle("Q2") + ylab("") + xlab("") +
  theme_tufte() +
  theme(
    axis.text.x = element_blank(), 
    axis.ticks.x = element_blank(),
    axis.text.y = element_blank(), 
    axis.ticks.y = element_blank()
  )

p3 <- plot(conditional_effects(WQ3gp), plot = FALSE)[[5]]  + 
  ylim(1,5) + ggtitle("Q3") + ylab("") + xlab("") +
  theme_tufte() +
  theme(
    axis.text.x = element_blank(), 
    axis.ticks.x = element_blank()
  )

p4 <- plot(conditional_effects(WQ4gp), plot = FALSE)[[5]] + 
  ylim(1,5) + ggtitle("Q4") + ylab("") + xlab("") +
  scale_x_continuous(name = "Week",
                     limits = c(1,12),
                     breaks = seq(from = 1, to = 12), 
                     labels = c("0", "1", "2", "3", "4",
                                "5", "6", "7", "8", "9",
                                "10", "11")) +
  theme_tufte() +
  theme(
    axis.text.y = element_blank(), 
    axis.ticks.y = element_blank()
  )

p5 <- plot(conditional_effects(WQ5gp), plot = FALSE)[[5]] + 
  ylim(1,5) + ggtitle("Q5") + ylab("") + xlab("") +
  scale_x_continuous(name = "Week",
                     limits = c(1,12),
                     breaks = seq(from = 1, to = 12), 
                     labels = c("0", "1", "2", "3", "4",
                                "5", "6", "7", "8", "9",
                                "10", "11")) + theme_tufte()

p1 + p2 + p3 + p4 + p5 + 
  plot_layout(ncol=2) + 
  plot_annotation(title = 'Weekly instrument')
```

In short, very little happening over time according to the weekly instrument.

## `daily` data {#daily}

### Prior and posterior predictive checks

Let's redo this but for the `daily` dataset.

```{r daily-pri, echo=TRUE, warning=FALSE, message=FALSE}
daily <- left_join(daily, pers, by = "ID")
daily$ID <- as.factor(daily$ID)
daily$date_s <- as.numeric(daily$date)
daily$Living14 <- as.numeric(daily$Living14)
daily <- daily[order(weekly$ID),]
daily$Seq <- sequence(tabulate(daily$ID))

p <- get_prior(resp ~ 1 + gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID), 
               data = daily, family = cumulative)
p$prior[1] <- "normal(0,2)"
p$prior[6] <- "normal(0,5)"
p$prior[17] <- "inv_gamma(1.6, 0.1)"
p$prior[18] <- "weibull(2,1)"

m_daily <- brm(resp ~ 1 + gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID), 
               data = daily, 
               family = cumulative,
               prior = p,
               sample_prior = "only",
               silent = TRUE, 
               refresh = 0)#, threads = threading(4))

pp_check(m_daily, type = "bars", nsamples = 100)
```

```{r daily, echo=TRUE, warning=FALSE, message=FALSE}
m_daily <- brm(resp ~ 1 + gp(Seq) + Age + Gender01 + Occupation + Living14 + (1 | ID), 
               data = daily, 
               family = cumulative,
               prior = p,
               control = list(adapt_delta=0.99),
               silent = TRUE, 
               refresh = 0)
```

```{r}
pp_check(m_daily, type = "bars", nsamples = 100)
```

### Diagnostics
```{r}
rstan::check_hmc_diagnostics(m_daily$fit)

# check rhat and ESS
if(max(rhat(eval(m_daily)), na.rm=T) >= 1.01) {
  print("Warning: Rhat >=1.01")
} else {
  print("All Rhat <1.01")
}

if(min(neff_ratio(eval(m_daily)), na.rm=T) <= 0.2) {
  print("Warning: ESS <=0.2")
} else {
  print("All ESS >0.2")
}
```

### Parameter estimates
Let's plot an interesting effect, which albeit is not significant has a tendency that's interesting.

```{r, warning=FALSE, message=FALSE}
plot(conditional_effects(m_daily), plot = FALSE)[[2]] +
  xlim(1,2.5) +
  scale_x_continuous(name=NULL, 
                     breaks = c(1,2), 
                     label = c("Man/\n transman","Woman/\n transwoman"), 
                     expand = c(0.08, 0)) +
  scale_y_continuous(name=NULL, breaks = c(6,7)) + 
  theme_tufte()
```

Next, look at the trend.

```{r, warning=FALSE, message=FALSE}
plot(conditional_effects(m_daily), plot = FALSE)[[5]] +
  xlab("Day") + ylab("") +
  theme_tufte()
```

One things clear, the uncertainty at the end makes an inferences useless.

## Multivariate models with temporal variable

We want a model that uses personal data (e.g., age) as predictors. The idea is to later see if any of the predictors have predictive capacity for our six different survey instruments. 

First, design a model with predictors from `personal` data and compare with our null model ($\mathcal{M}_0$), together with our indicator $t$ for time, and a varying intercept `ID` that varies depending on subject.

```{r predictors-pers, echo=TRUE, warning=FALSE, message=FALSE}
bf1 <- bf(mvbind(MAASQ116,
                 MAASQ216,
                 MAASQ316,
                 MAASQ416,
                 MAASQ516,
                 MAASQ616,
                 MAASQ716,
                 MAASQ816,
                 MAASQ916,
                 MAASQ1016,
                 MAASQ1116,
                 MAASQ1216,
                 MAASQ1316,
                 MAASQ1416,
                 MAASQ1516) ~ 
            1 + Age + Gender01 + Occupation + Living14 + t + (1|c|ID))

m_pers <- brm(bf1,
    family = cumulative,
    data = d,
    silent = TRUE,
    refresh = 0)#,
    #threads = threading(4))

m_pers <- add_criterion(m_pers, criterion = "loo")

# compare the new model with our null model, it should hopefully be better...
(l <- loo_compare(m0, m_pers))
```

Calculating the credible interval ($z_{95\%}=1.96$) we can see that it doesn't cross zero, i.e., adding these predictors makes the relative out of sample prediction capability jump up even though we add seven population-level predictors and one group-level predictor (`Living14` contains three parameters to estimate).

```{r ci-loo, echo=TRUE, warnings=FALSE}
l[2,1] + c(-1,1) * 1.96 * l[2,2]
```

### Prior and posterior predictive checks

Let's now sample all models with the same predictors we used above (visual prior and posterior predictive checks were done for each model).

```{r m-maas, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# MAAS
#
################################################################################
bf1 <- bf(mvbind(MAASQ116,
                 MAASQ216,
                 MAASQ316,
                 MAASQ416,
                 MAASQ516,
                 MAASQ616,
                 MAASQ716,
                 MAASQ816,
                 MAASQ916,
                 MAASQ1016,
                 MAASQ1116,
                 MAASQ1216,
                 MAASQ1316,
                 MAASQ1416,
                 MAASQ1516) ~ 
            1 + Age + Gender01 + Occupation + Living14 + t + (1 |c| ID))

# Prior predictive checks have been conducted and the probability mass 
# is distributed evenly on the outcome space
p <- get_prior(bf1, data=d, family=cumulative) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))
  
         
m_maas <- brm(bf1,
    family = cumulative,
    data = d,
    prior = p,
    #sample_prior = "only", # use if you only want to sample from prior
    silent = TRUE,
    refresh = 0)#,
    #threads = threading(4))

# use the below to do prior and posterior predictive checks
# change resp to the response variable you want to check 
# pp_check(m_maas, resp = "MAASQ116", type = "bars, nsamples = 250) 
```

```{r m-spane, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# SPANE
#
################################################################################

bf1 <- bf(mvbind(SPANEQ115,
                 SPANEQ215,
                 SPANEQ315,
                 SPANEQ415,
                 SPANEQ515,
                 SPANEQ615,
                 SPANEQ715,
                 SPANEQ815,
                 SPANEQ915,
                 SPANEQ1015,
                 SPANEQ1115,
                 SPANEQ1215) ~ 
            1 + Age + Gender01 + Occupation + Living14 + t + (1 |c| ID))

p <- get_prior(bf1, data=d, family=cumulative) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_spane <- brm(bf1,
    family = cumulative,
    data = d,
    prior = p,
    # sample_prior = "only", # use if you only want to sample from prior
    silent = TRUE,
    refresh = 0)#,
    #threads = threading(4))

# use the below to do prior and posterior predictive checks
# change resp to the response variable you want to check 
# pp_check(m_spane, resp = "SPANEQ115", type = "bars", nsamples = 250) 
```

```{r m-pwb, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# PWB
#
################################################################################

bf1 <- bf(mvbind(PWBQ117,
                 PWBQ217,
                 PWBQ317,
                 PWBQ417,
                 PWBQ517,
                 PWBQ617,
                 PWBQ717,
                 PWBQ817) ~ 
            1 + Age + Gender01 + Occupation + Living14 + t + (1 |c| ID))

p <- get_prior(bf1, data=d, family=cumulative) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_pwb <- brm(bf1,
    family = cumulative,
    data = d,
    prior = p,
    # sample_prior = "only", # use if you only want to sample from prior
    silent = TRUE,
    refresh = 0)#,
    #threads = threading(4))

# pp_check(m_pwb, resp = "PWBQ117", type = "bars", nsamples = 250) 
```

```{r m-pst, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# PST
#
################################################################################
# Here we move to a bernoulli since we have 0/1 outcome
bf1 <- bf(mvbind(PSTQ101,
                 PSTQ201,
                 PSTQ301,
                 PSTQ401,
                 PSTQ501,
                 PSTQ601,
                 PSTQ701,
                 PSTQ801,
                 PSTQ901,
                 PSTQ1001,
                 PSTQ1101,
                 PSTQ1201,
                 PSTQ1301,
                 PSTQ1401,
                 PSTQ1501,
                 PSTQ1601,
                 PSTQ1701,
                 PSTQ1801,
                 PSTQ1901,
                 PSTQ2001,
                 PSTQ2101,
                 PSTQ2201) ~ 
            1 + Age + Gender01 + Occupation + Living14 + t + (1 |c| ID))

p <- get_prior(bf1, data=d, family=bernoulli) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_pst <- brm(bf1,
    family = bernoulli,
    data = d,
    prior = p,
    # sample_prior = "only",
    silent = TRUE,
    refresh = 0
    )

# pp_check(m_pst, resp = "PSTQ101", type = "bars", nsamples = 250) 
```

```{r m-se, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# SE - two models (Cumulative and Bernoulli), both multivariate 
#
################################################################################
# NOTE: the first two questions can be analyzed as Bernoulli 
bf1 <- bf(mvbind(#SEQ114, # this and the next outcome only has two categories
                 #SEQ214,
                 SEQ314,
                 SEQ414,
                 SEQ514,
                 SEQ614,
                 SEQ714,
                 SEQ814,
                 SEQ914,
                 SEQ1014) ~
            1 + Age + Gender01 + Occupation + Living14 + t + (1 |c| ID))

p <- get_prior(bf1, data=d, family=cumulative) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_se <- brm(bf1,
    family = cumulative,
    data = d,
    prior = p,
    # sample_prior = "only",
    silent = TRUE,
    refresh = 0)#,
    #threads = threading(4))

# pp_check(m_seq, resp = "SEQ314", type = "bars", nsamples = 250) 

# next take the two questions that only had answers on two levels
bf1 <- bf(mvbind(SEQ114,
                 SEQ214) ~
            1 + Age + Gender01 + Occupation + Living14 + t + (1 |c| ID))

p <- get_prior(bf1, data=d, family=bernoulli) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_se2 <- brm(bf1,
    family = bernoulli,
    data = d,
    prior = p,
    # sample_prior = "only",
    silent = TRUE,
    refresh = 0
    )

# pp_check(m_seq2, resp = "SEQ114", type = "bars", nsamples = 250) 
```

```{r m-pph, echo=TRUE, warning=FALSE, message=FALSE}
################################################################################
#
# PPHQ
#
################################################################################


bf1 <- bf(mvbind(PPHQ115,
                 PPHQ215,
                 PPHQ315,
                 PPHQ415,
                 PPHQ515,
                 PPHQ615,
                 PPHQ715,
                 PPRQ1110,
                 PPRQ2110,
                 PPRQ3110,
                 PPOQ117
                 ) ~ 
            1 + Age + Gender01 + Occupation + Living14 + t + (1 |c| ID))

p <- get_prior(bf1, data=d, family=cumulative) %>%
  mutate(prior = ifelse(class == "b", "normal(0,3)", prior)) %>%
  mutate(prior = ifelse(class == "cor", "lkj(2)", prior)) %>%
  mutate(prior = ifelse(class == "Intercept", "normal(0,5)", prior)) %>%
  mutate(prior = ifelse(class == "sd", "weibull(2,1)", prior))

m_pph <- brm(bf1,
    family = cumulative,
    data = d,
    prior = p,
    # sample_prior = "only",
    silent = TRUE,
    refresh = 0,
    # threads = threading(4)
    )

# pp_check(m_pphq, resp = "PPHQ115", type = "bars", nsamples = 250) 
```

So we have now sampled seven models. For each instrument we have one multivariate model ($>1$ outcome), where we also estimate the correlation between the outcome given the subject's ID. 

Most of the models are using, as we've already discussed, the Cumulative family. However, in a few cases we use the Bernoulli family. First, we use it for outcomes that were binary (i.e., Yes/No outcomes). Second, we use it for two questions in the SE instrument ($\mathcal{M}_{\text{SE}2}$), which only had empirical outcomes on two levels. 

Before we put any trust in these models we need to check a number of diagnostics.

### Diagnostics

First, we check general HMC diagnostics. Second, we check that $\widehat{R} \leq 1.01$ and that the effective sample size (ESS) is $\geq 0.2$.

```{r diagnostics, echo=TRUE}
models <- list(m_maas, m_spane, m_pwb, m_pst, m_se, m_se2, m_pph)

# Check divergences, tree depth, energy for each model
for(m in models) {
  rstan::check_hmc_diagnostics(eval(m)$fit)
}

# Check rhat and neff
for(m in models) {
  if(max(rhat(eval(m)), na.rm=T) >= 1.01) # diag in corr matrix always NA
    print("Warning: Rhat >= 1.01")
  if(min(neff_ratio(eval(m)), na.rm=T) <= 0.2) # diag in corr matrix always NA
    print("Warning: ESS <= 0.2")
}
```

Hamiltonian Monte Carlo diagnostics indicate all is well, $\widehat{R} \leq 1.01$, and $\text{ESS} \geq 0.2$. One can also check traceplots for all models (i.e., using `plot(model)`).

### Parameter estimates

First, let's summarize what we have so far:

1. Daily trends modeled with Gaussian Processes (results in Sect.~\@ref(daily)).
2. Weekly trends modeled with Gaussian Processes (results in Sect.~\@ref(weekly)).
3. Seven multivariate models with temporal variable to analyze entry/exit. Additionally, we have an eight model for analyzing two questions (1--2) in the SE instrument (using a Bernoulli likelihood).

We can now investigate which, if any, parameters are significant on the 95%-level for the third item. Any parameters that are significant could warrant further analysis.


# Computational environment

```{r}
print(sessionInfo(), locale=FALSE)
```

Check how much time it takes to compile this document.

```{r}
end.time <- Sys.time()
round((end.time - start.time), 1)
```

# References

