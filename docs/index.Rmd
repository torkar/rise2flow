---
title: "Rise 2 Flow"
author: "B. Penzenstadler & R. Torkar"
date: "First version: 2020-12-26. Current version: `r Sys.Date()`."
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    scroll_highlight: yes
    number_sections: true
bibliography: references.bib
csl: elsevier-harvard.csl
link-citations: true
linkcolor: blue
---

```{r setup, include=FALSE}
start.time <- Sys.time()
knitr::opts_chunk$set(echo = FALSE)
```

```{r setup2, echo=FALSE, message=FALSE}
library("brms") 
library("plyr") # rm non-duplicates
library("tidyverse") 
library("bayesplot")
library("ggplot2")
library("patchwork") 
library("openxlsx")
library("data.table")
rstan::rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

# Introduction
The Rise 2 Flow study used a number of instruments during the entry, exit, and weekly sessions (additionally personal data was collected during the entry session).

For entry and exit sessions six instruments were used:

* Mindful attention awareness scale (MAAS).^[https://ppc.sas.upenn.edu/resources/questionnaires-researchers/mindful-attention-awareness-scale]
* Scale of positive and negative experience (SPANE).^[https://www.midss.org/content/scale-positive-and-negative-experience-spane-0]
* Personal wellbeing index (PWB).^[http://www.acqol.com.au/instruments]
* Positive thinking (PST).^[https://www.psytoolkit.org/survey-library/pts.html]
* Self efficacy (SE).^[https://sparqtools.org/mobility-measure/new-general-self-efficacy-scale/]
* Perceived productivity (PP).^[https://www.hcp.med.harvard.edu/hpq/info.php]

In addition, a seventh instrument, mini-IPIP, was added to the exit session to control for personality type.^[https://ipip.ori.org/MiniIPIPKey.htm]

For the weekly sessions the WHO-5 well-being index was used (WHO-5).^[https://www.psykiatri-regionh.dk/who-5/who-5-questionnaires/Pages/default.aspx]

To summarize, the study was executed according to,

1. An entry survey, at time $t_0$
2. A weekly survey, at time $t_{{t_0 + 1}}, \ldots, t_{{t_0+13}}$
3. An exit survey, at time $t_1$

The main question the study tries to answer is: **Is there a difference in the responses (i.e., higher/lower values on responses), across all or among some instruments, over time?**

In order to answer that question we can first of all compare outcomes of $t_0$ and $t_1$, and contrast with personal data, e.g., age, gender, IPIP. Next, the weekly session can be used to investigate the trend over time, and perhaps see where a noticeable effect, if it exists, shows up.

# Data cleaning

First we load all five datasets. For each dataset, make sure we set correct variable types.

```{r load, echo=TRUE}
entry <- read.xlsx("../data/R2F Quant Comp Data Entry.xlsx")
exit <- read.xlsx("../data/R2F Quant Comp Data Exit.xlsx")
weekly <- read.xlsx("../data/R2F Quant Weekly.xlsx")
ipip <- read.xlsx("../data/R2F IPIP.xlsx")
pers <- read.xlsx("../data/R2F Pers Data.xlsx") # personal data
```

## Data cleaning of `entry` and `exit` datasets

We need to set a number of columns as factors (ordered factors in many cases). For a few statements below we also switch the order of the factors (see comment below). The reason we do this is that we will design a multilevel model, and if the questions go in opposite directions, partial pooling works against us.

Additionally, when we have Yes/No answers, as we do in some questions below, we refrain from setting them as indicator variables, i.e., $0/1$, and instead use $1/2$. The main reason we do this is that we cannot assume there is more uncertainty about one of the categories, and it will make it easier to set appropriate priors [see @mcelreath20rethinking, pp. 154--155].

First we clearn the `entry` dataset.

```{r clean-entry, echo=TRUE, warning=FALSE}
for(j in 3:17){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("Almost never", "Very infrequently", "Somewhat infrequently", "Somewhat frequently", "Very frequently", "Almost always"), ordered = TRUE))
}

for(j in 18:29){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("Very rarely or never", "Rarely", "Sometimes", "Often", "Very often or always"), ordered = TRUE))
}

for(j in 30:37){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("Strongly disagree", "Disagree", "Slightly disagree", "Mixed or neither agree nor disagree", "Slightly agree", "Agree", "Strongly agree"), ordered = TRUE))
}

# No == 1, Yes == 2 (never use 0/1 since we cannot assume there is more 
# uncertainty about one of the categories)
for(j in c(39,40,42,43,45,46,50,51,53,55,59)){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("No","Yes")))
}

# switch the order here since questions are framed negatively (partial pooling)
# No = 2, Yes = 1
for(j in c(38,41,44,47,48,49,52,54,56,57,58)){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("Yes","No")))
}

for(j in 60:69){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("Hardly true","Rather true","Exactly true"), ordered = TRUE))
}

for(j in 70:76){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("None of the time","A little of the time","Some of the time","Most of the time","All of the time"), ordered = TRUE))
}

for(j in 77:79){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("1","2","3","4","5","6","7","8","9","10"), ordered = TRUE))
}

for(j in 80:80){
  set(entry, i=NULL, j=j, value=factor(entry[[j]], levels = c("You were a lot worse than other workers","You were a little worse than other workers","You were somewhat worse than other workers","You were about average","You were somewhat better than other workers","You were a little better than other workers","You were a lot better than other workers"), ordered = TRUE))
}
```

Next, we clean the `exit` dataset, which consists of the same variables as above.

```{r clean-exit, echo=TRUE, warning=FALSE}
for(j in 3:17){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("Almost never", "Very infrequently", "Somewhat infrequently", "Somewhat frequently", "Very frequently", "Almost always"), ordered = TRUE))
}

for(j in 18:29){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("Very rarely or never", "Rarely", "Sometimes", "Often", "Very often or always"), ordered = TRUE))
}

for(j in 30:37){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("Strongly disagree", "Disagree", "Slightly disagree", "Mixed or neither agree nor disagree", "Slightly agree", "Agree", "Strongly agree"), ordered = TRUE))
}

# No == 1, Yes == 2 (never use 0/1 since we cannot assume there is more 
# uncertainty about one of the categories)
for(j in c(39,40,42,43,45,46,50,51,53,55,59)){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("No","Yes")))
}

# switch the order here since questions are framed negatively (partial pooling)
# No = 2, Yes = 1
for(j in c(38,41,44,47,48,49,52,54,56,57,58)){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("Yes","No")))
}

for(j in 60:69){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("Hardly true","Rather true","Exactly true"), ordered = TRUE))
}

for(j in 70:76){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("None of the time","A little of the time","Some of the time","Most of the time","All of the time"), ordered = TRUE))
}

for(j in 77:79){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("1","2","3","4","5","6","7","8","9","10"), ordered = TRUE))
}

for(j in 80:80){
  set(exit, i=NULL, j=j, value=factor(exit[[j]], levels = c("You were a lot worse than other workers","You were a little worse than other workers","You were somewhat worse than other workers","You were about average","You were somewhat better than other workers","You were a little better than other workers","You were a lot better than other workers"), ordered = TRUE))
}
```

## Data cleaning of `weekly` dataset

The `weekly` dataset contains five columns of the same type, which we set as ordered categorical.

```{r clean-weekly, warnings = FALSE, echo = TRUE}
for(j in 4:8){
  set(weekly, i=NULL, j=j, value=factor(weekly[[j]], levels = c("At not time", "Less than half of the time", "Some of the time", "More than half of the time",  "Most of the time", "All of the time"), ordered = TRUE))
}
```

## Data cleaning of `ipip` dataset

The mini-IPIP instrument uses only five levels for all 20 questions (ordered categorical).

```{r clean-ipip, warnings = FALSE, echo = TRUE}
for(j in 3:22){
  set(ipip, i=NULL, j=j, value=factor(ipip[[j]], levels = c("Disagree", "Somewhat disagree", "Neither agree nor disagree", "Somewhat agree", "Agree"), ordered = TRUE))
}
```

## Data cleaning of `pers` dataset

In the `pers` dataset we have a mix of variable types we need to deal with. `Age` should be scaled, `Gender` and `Occupation` set to 1/2, and `Living conditions` set to factors (unordered).

```{r clean-pers, warnings = FALSE, echo = TRUE}
# convert Age to numeric and standardize (note we have two NAs, so we suppress the warning we get)
suppressWarnings(pers$Age <- scale(as.numeric(pers$Age)))

# set 1/2 as indicators for gender
pers$Gender_0_1 <- ifelse(pers$Gender_0_1 == "Man/Transman", 1, 2)

# many categories exist for occupation, but let's simplify this so we can 
# use this variable for something. Indicate if they are students or not.
pers$Occupation <- ifelse(pers$Occupation == "Student", 1, 2)

# make living condition a categorical factor (unordered)
pers$Living_1_4 <- factor(pers$Living_1_4, levels = c("I live by myself", "I live in shared housing", "I live with a partner", "I live with my family"))

# remove the last three columns since we have >64% NAs
pers[,7:9] <- NULL
```

## Missingness analysis

Check how many cells are NA.

```{r missingness, echo=TRUE}
table(is.na(entry))
table(is.na(exit))
table(is.na(weekly))
table(is.na(pers))
```

Clearly we have missing data here, but it's only a few percentages ($0.6$--$1.8$%). Let's use complete case analysis for now (i.e., remove all rows containing NAs). Later, if needed, we can model the missingness in a principled Bayesian way.

```{r rm-NAs, echo=TRUE}
entry <- entry[complete.cases(entry), ]
exit <- exit[complete.cases(exit), ]
weekly <- weekly[complete.cases(weekly), ]
pers <- pers[complete.cases(pers), ]
```

Remember, the main question the study tries to answer is: **Is there a difference in the responses (i.e., higher/lower values on responses), across all or among some instruments, over time?** This means that for now we can discard of the weekly data and instead focus on the entry and exit instruments, together with personal data (i.e., age, gender, occupation, and living conditions).

In order for us to conduct inferences along this line of thinking, we will make use of dummy variable regression estimators (DVRE), which is numerically identical to deviation score estimators. The DVRE approach dummy encodes our time variable $t$ and sets an index $0/1$, where $t_0 = 0$ and $t_1 = 1$. In short, each subject (`ID`) will have two rows where one row is the entry instrument $t = 0$, and one row has the exit instrument $t = 1$. We'll create six datasets which are divided according to each instrument we use as outcome (MAAS, SPANE, PWB, PST, SE, and PP), and then see if our predictors are useful for predicting the outcome (i.e., is there a significant difference in the $\beta$ estimators) and then also investigate if the outcome at $t_0$ equals $t_1$ (and if they aren't the same, how much do they differ?)

```{r split_join, echo=TRUE}
# create new column t, and set to 0 or 1
entry$t <- 0
exit$t <- 1

# Remove all suffixes in both files so we have the same column names
colnames(entry) <- gsub('_en', '', colnames(entry))
colnames(exit) <- gsub('_ex', '', colnames(exit))

# add rows of entry and exit
d <- rbind(entry, exit)

# keep only rows if they show up twice, so we have a within-measurement of each # individual at time t_0 and t_1
d <- ddply(d, .(ID), function(x){
    if(nrow(x)==1){
        return(NULL)
    }
    else{
        return(x)
    }
})

table(d$t)
```

We have $13$ individuals with entry and exit surveys completely filled out.

# Model design

## Prior predictive checks

## Sampling

## Posterior predictive checks

## Diagnostics

# Model comparison

# Inference

# Computational environment
```{r}
print(sessionInfo(), locale=FALSE)
```

Check how much time it takes to compile this document.

```{r}
end.time <- Sys.time()
round((end.time - start.time), 3)
```

# References
