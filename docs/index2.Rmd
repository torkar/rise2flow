---
title: "Rise 2 Flow: Take II"
subtitle: "A replication package"
author: "Birgit Penzenstadler, Cristina Martinez Montez, and Richard Torkar"
date: "First version: 2021-05-05. Current version: `r Sys.time()`."
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    scroll_highlight: yes
    number_sections: true
bibliography: references.bib
csl: elsevier-harvard.csl
link-citations: true
linkcolor: blue
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

```{r setup2, echo=FALSE, message=FALSE}
library("brms") 
library("plyr") # rm non-duplicates
library("tidyverse") 
library("bayesplot")
library("latex2exp")
library("ggplot2")
library("ggthemes")
library("patchwork") 
library("openxlsx")
library("data.table")
library("here") # make sure Rmd and Rproj root is the same
rstan::rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

# Introduction

During spring 2021 the Rise 2 Flow study was replicated in yet another experiment `E2`. The setup and execution was very similar to the first instance (`E1`) of the experiment. In the `data/` directory one can find data for both instances `E1/` and `E2/`. In the root of the `data/` directory one can find one XLS file with all relevant data assembled.

The purpose of this document is to show how the analysis of the experiments was done. With this replication package anyone can download and rerun the analysis, and check our assumptions.

The experiment used a number of instruments during the entry, exit, and weekly sessions (additionally personal data was collected during the entry session).

For entry and exit sessions six instruments were used:

* Mindful attention awareness scale (MAAS).^[https://ppc.sas.upenn.edu/resources/questionnaires-researchers/mindful-attention-awareness-scale]
* Scale of positive and negative experience (SPANE).^[https://www.midss.org/content/scale-positive-and-negative-experience-spane-0]
* Personal well-being index (PWB).^[http://www.acqol.com.au/instruments]
* Positive thinking (PST).^[https://www.psytoolkit.org/survey-library/pts.html]
* Self efficacy (SE).^[https://sparqtools.org/mobility-measure/new-general-self-efficacy-scale/]
* Perceived productivity (PP).^[https://www.hcp.med.harvard.edu/hpq/info.php]

For the weekly sessions the WHO-5 well-being index was used (WHO-5).^[https://www.psykiatri-regionh.dk/who-5/who-5-questionnaires/Pages/default.aspx]

To summarize, the experiments were executed according to,

1. An entry survey, at time $t_0$ (MAAS, etc.) with personal data
2. A weekly survey, at time $t_{1}, \ldots, t_{n}$
3. Daily surveys
4. An exit survey, at time $t_{n+1}$ (MAAS, etc.)

The main question the study tries to answer is: **Is there a difference in the responses (i.e., higher/lower values on responses), across all or among some instruments, over time?**

In order to answer that question we can first of all compare outcomes of $t_0$ and $t_1$, and condition on personal data, e.g., age and gender. Next, the weekly session can be used to analyze the trend over time, and perhaps see where a noticeable effect, if it exists, shows up.

```{r load_data, echo=TRUE}
d <- read.csv(here("data/cleanedData.csv"), row.names = 1)
dim(d)
```

In total we have `r dim(d)[1]` rows and `r dim(d)[2]` columns; so not bad at all actually ($N=187$). Each row corresponds to one subject answering either the entry ($t_0$) or the exit ($t_1$) survey. In some cases we have subjects that have only answered one of them!

```{r}
table(table(d$ID) >1)
```

So, $105$ subjects filled out the survey once, and $41$ filled out the entry *and* exit surveys.

## Data cleaning

### Entry and exit instruments

The first thing we should do is clean the data. Yes, boring but always needed to ensure that we have a consistent data set.

We need to, at a minimum, 1. check the subject ID to note any funkiness, 2. check each predictor (column) and see that only allowed answers exist, 3. encode each column (e.g., standardize continuous values, use factors for Likert scale, and, in general, set correct data types).

There should not be more than $>2$ rows per subject and it should be encoded as an integer for reasons of anonymity.

```{r}
max(table(d$ID))
typeof(d$ID)
```

For each column (variable) we check which values it has and then code it correctly,

```{r}
# MAAS instrument
for(j in 2:16){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("Almost never", "Very infrequently", "Somewhat infrequently", "Somewhat frequently", "Very frequently", "Almost always"), ordered = TRUE))
}

# SPANE instrument
for(j in 17:28){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("Very rarely or never", "Rarely", "Sometimes", "Often", "Very often or always"), ordered = TRUE))
}

# PWB instrument
for(j in 29:36){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("Strongly disagree", "Disagree", "Slightly disagree", "Mixed or neither agree nor disagree", "Slightly agree", "Agree", "Strongly agree"), ordered = TRUE))
}

# PST instrument
for(i in 37:58)
  d[,eval(i)] <- ifelse(d[eval(i)] == 'Yes', 1, 0)

# SEQ instrument
for(j in 59:68){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("Not true","Hardly true","Rather true","Exactly true"), ordered = TRUE))
}

# PP instrument
for(j in 69:75){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("None of the time","A little of the time","Some of the time","Most of the time","All of the time"), ordered = TRUE))
}
for(j in 76:78){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("1","2","3","4","5","6","7","8","9","10"), ordered = TRUE))
}
for(j in 79:79){
  set(d, i=NULL, j=j, value=factor(d[[j]], levels = c("You were a lot worse than other workers","You were a little worse than other workers","You were somewhat worse than other workers","You were about average","You were somewhat better than other workers","You were a little better than other workers","You were a lot better than other workers"), ordered = TRUE))
}

# make sure Age is standardized
d$Age <- scale(d$Age)

# and the rest of the variables look ok :)
str(d)
```

To summarize, in the first column we have subject ID, then the MAAS instrument ($15$ questions), SPANE ($12$), PWB ($8$), PST ($22$), SE ($10$), PP ($11$), age (standardized), gender ($1/2$), occupation (student or non-students, $1/2$), living condition (four unordered categories), temporal variable ($0/1$ for $t_0 / t_1$), and experiment ($1/2$ for first or second experiment).

### Daily and weekly data

```{r}
weekly <- read.xlsx(here("../data/R2F Quant Weekly.xlsx"), detectDates = T)
daily <- read.xlsx(here("../data/R2F Daily.xlsx"), detectDates = T)

for(j in 4:8){
  set(weekly, i=NULL, j=j, value=factor(weekly[[j]], levels = c("At no time", "Less than half of the time", "Some of the time", "More than half of the time",  "Most of the time", "All of the time"), ordered = TRUE))
}

# check this for daily and weekly 
daily$ID <- as.factor(daily$ID)
daily <- daily[order(daily$ID),]
daily$Seq <- sequence(tabulate(daily$ID))
# drop column 2:3
daily <- daily[-c(2:3)]
```

```{r}
daily[rowSums(is.na(daily)) > 0,]

# so some have no response recorded. Let's remove
daily <- daily[complete.cases(daily), ]
```


# Computational environment

```{r}
print(sessionInfo(), locale=FALSE)
```
